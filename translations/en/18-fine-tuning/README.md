<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "807f0d9fc1747e796433534e1be6a98a",
  "translation_date": "2025-10-17T22:33:23+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "en"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.en.png)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Fine-Tuning Your LLM

Using large language models to build generative AI applications presents new challenges. One major issue is ensuring the quality of responses (accuracy and relevance) in the content generated by the model for a specific user request. In previous lessons, we explored techniques like prompt engineering and retrieval-augmented generation, which aim to address this issue by _modifying the prompt input_ to the existing model.

In today's lesson, we will discuss a third technique, **fine-tuning**, which tackles the challenge by _retraining the model itself_ with additional data. Let’s dive into the details.

## Learning Objectives

This lesson introduces the concept of fine-tuning for pre-trained language models, examines the benefits and challenges of this approach, and provides guidance on when and how to use fine-tuning to enhance the performance of your generative AI models.

By the end of this lesson, you should be able to answer the following questions:

- What is fine-tuning for language models?
- When, and why, is fine-tuning useful?
- How can I fine-tune a pre-trained model?
- What are the limitations of fine-tuning?

Ready? Let’s get started.

## Illustrated Guide

Want to get an overview of what we’ll cover before diving in? Check out this illustrated guide that outlines the learning journey for this lesson—from understanding the core concepts and motivation for fine-tuning to learning the process and best practices for executing the fine-tuning task. This is an exciting topic to explore, so don’t forget to visit the [Resources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) page for additional links to support your self-guided learning journey!

![Illustrated Guide to Fine Tuning Language Models](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.en.png)

## What is fine-tuning for language models?

Large language models are, by definition, _pre-trained_ on vast amounts of text from diverse sources, including the internet. As we’ve learned in previous lessons, techniques like _prompt engineering_ and _retrieval-augmented generation_ are used to improve the quality of the model’s responses to user queries ("prompts").

A common prompt-engineering technique involves providing the model with more guidance on what is expected in the response, either by giving _instructions_ (explicit guidance) or _providing a few examples_ (implicit guidance). This is known as _few-shot learning_, but it has two limitations:

- Model token limits can restrict the number of examples you can provide, reducing effectiveness.
- Model token costs can make it expensive to include examples in every prompt, limiting flexibility.

Fine-tuning is a widely used practice in machine learning systems where a pre-trained model is retrained with new data to improve its performance on a specific task. In the context of language models, fine-tuning involves retraining the pre-trained model _with a curated set of examples for a specific task or application domain_ to create a **custom model** that is more accurate and relevant for that particular task or domain. A secondary benefit of fine-tuning is that it can reduce the number of examples needed for few-shot learning, thereby lowering token usage and associated costs.

## When and why should we fine-tune models?

In _this_ context, fine-tuning refers to **supervised** fine-tuning, where retraining is done by **adding new data** that was not part of the original training dataset. This differs from unsupervised fine-tuning, where the model is retrained on the original data but with different hyperparameters.

It’s important to note that fine-tuning is an advanced technique that requires a certain level of expertise to achieve the desired results. If done incorrectly, it may not yield the expected improvements and could even degrade the model’s performance for your targeted domain.

Before learning "how" to fine-tune language models, you need to understand "why" you should pursue this approach and "when" to initiate the fine-tuning process. Start by asking yourself these questions:

- **Use Case**: What is your _use case_ for fine-tuning? What aspect of the current pre-trained model do you want to improve?
- **Alternatives**: Have you tried _other techniques_ to achieve the desired outcomes? Use them to establish a baseline for comparison.
  - Prompt engineering: Experiment with techniques like few-shot prompting using examples of relevant prompt responses. Assess the quality of the responses.
  - Retrieval-Augmented Generation: Enhance prompts with query results retrieved from your data. Evaluate the quality of the responses.
- **Costs**: Have you assessed the costs of fine-tuning?
  - Tunability: Is the pre-trained model available for fine-tuning?
  - Effort: What is required to prepare training data, evaluate, and refine the model?
  - Compute: What are the resources needed to run fine-tuning jobs and deploy the fine-tuned model?
  - Data: Do you have access to sufficient high-quality examples to make fine-tuning impactful?
- **Benefits**: Have you confirmed the advantages of fine-tuning?
  - Quality: Does the fine-tuned model outperform the baseline?
  - Cost: Does it reduce token usage by simplifying prompts?
  - Extensibility: Can the base model be adapted for new domains?

By answering these questions, you should be able to determine whether fine-tuning is the right approach for your use case. Ideally, this approach is valid only if the benefits outweigh the costs. Once you decide to proceed, it’s time to consider _how_ you can fine-tune the pre-trained model.

Want more insights into the decision-making process? Watch [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## How can we fine-tune a pre-trained model?

To fine-tune a pre-trained model, you need:

- A pre-trained model to fine-tune
- A dataset for fine-tuning
- A training environment to execute the fine-tuning job
- A hosting environment to deploy the fine-tuned model

## Fine-Tuning In Action

The following resources provide step-by-step tutorials to guide you through a real example using a selected model with a curated dataset. To follow these tutorials, you’ll need an account with the specific provider, along with access to the relevant model and datasets.

| Provider     | Tutorial                                                                                                                                                                       | Description                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [How to fine-tune chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | Learn to fine-tune a `gpt-35-turbo` for a specific domain ("recipe assistant") by preparing training data, running the fine-tuning job, and using the fine-tuned model for inference.                                                                                                                                                                                                                                              |
| Azure OpenAI | [GPT 3.5 Turbo fine-tuning tutorial](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Learn to fine-tune a `gpt-35-turbo-0613` model **on Azure** by taking steps to create & upload training data, run the fine-tuning job. Deploy & use the new model.                                                                                                                                                                                                                                                                 |
| Hugging Face | [Fine-tuning LLMs with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | This blog post walks you through fine-tuning an _open LLM_ (e.g., `CodeLlama 7B`) using the [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) library & [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) with open [datasets](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) on Hugging Face. |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| 🤗 AutoTrain | [Fine-tuning LLMs with AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | AutoTrain (or AutoTrain Advanced) is a Python library developed by Hugging Face that allows fine-tuning for many different tasks, including LLM fine-tuning. AutoTrain is a no-code solution, and fine-tuning can be done in your own cloud, on Hugging Face Spaces, or locally. It supports both a web-based GUI, CLI, and training via YAML config files.                                                                               |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Assignment

Choose one of the tutorials above and follow the steps. _We may replicate a version of these tutorials in Jupyter Notebooks in this repo for reference only. Please use the original sources directly to access the latest versions_.

## Great Work! Continue Your Learning.

After completing this lesson, explore our [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) to further enhance your knowledge of Generative AI!

Congratulations!! You’ve completed the final lesson from the v2 series for this course! Don’t stop learning and building. \*\*Check out the [RESOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) page for additional suggestions on this topic.

Our v1 series of lessons has also been updated with more assignments and concepts. Take a moment to refresh your knowledge—and please [share your questions and feedback](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) to help us improve these lessons for the community.

---

**Disclaimer**:  
This document has been translated using the AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator). While we aim for accuracy, please note that automated translations may include errors or inaccuracies. The original document in its native language should be regarded as the authoritative source. For critical information, professional human translation is advised. We are not responsible for any misunderstandings or misinterpretations resulting from the use of this translation.