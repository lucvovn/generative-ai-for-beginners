<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8e8d1f6a63da606af7176a87ff8e92b6",
  "translation_date": "2025-10-18T00:19:43+00:00",
  "source_file": "17-ai-agents/README.md",
  "language_code": "hi"
}
-->
[![ओपन सोर्स मॉडल्स](../../../translated_images/17-lesson-banner.a5b918fb0920e4e6d8d391a100f5cb1d5929f4c2752c937d40392905dec82592.hi.png)](https://youtu.be/yAXVW-lUINc?si=bOtW9nL6jc3XJgOM)

## परिचय

AI एजेंट्स जनरेटिव AI में एक रोमांचक विकास का प्रतिनिधित्व करते हैं, जो बड़े भाषा मॉडल्स (LLMs) को सहायक से ऐसे एजेंट्स में बदलने में सक्षम बनाते हैं जो कार्य कर सकते हैं। AI एजेंट फ्रेमवर्क्स डेवलपर्स को ऐसे एप्लिकेशन बनाने में सक्षम बनाते हैं जो LLMs को टूल्स और स्टेट मैनेजमेंट तक पहुंच प्रदान करते हैं। ये फ्रेमवर्क्स दृश्यता को भी बढ़ाते हैं, जिससे उपयोगकर्ता और डेवलपर्स LLMs द्वारा योजनाबद्ध कार्यों की निगरानी कर सकते हैं और अनुभव प्रबंधन में सुधार कर सकते हैं।

इस पाठ में निम्नलिखित विषयों को शामिल किया जाएगा:

- समझना कि AI एजेंट क्या है - AI एजेंट वास्तव में क्या है?
- चार अलग-अलग AI एजेंट फ्रेमवर्क्स का अन्वेषण करना - उन्हें क्या अनोखा बनाता है?
- इन AI एजेंट्स को विभिन्न उपयोग मामलों में लागू करना - हमें AI एजेंट्स का उपयोग कब करना चाहिए?

## सीखने के लक्ष्य

इस पाठ को पूरा करने के बाद, आप सक्षम होंगे:

- समझा सकें कि AI एजेंट्स क्या हैं और उनका उपयोग कैसे किया जा सकता है।
- कुछ लोकप्रिय AI एजेंट फ्रेमवर्क्स के बीच के अंतर को समझें और वे कैसे अलग हैं।
- समझें कि AI एजेंट्स कैसे कार्य करते हैं ताकि उनके साथ एप्लिकेशन बनाए जा सकें।

## AI एजेंट्स क्या हैं?

AI एजेंट्स जनरेटिव AI की दुनिया में एक बहुत ही रोमांचक क्षेत्र हैं। इस उत्साह के साथ कभी-कभी शब्दों और उनके उपयोग में भ्रम भी आता है। चीजों को सरल और अधिकांश टूल्स को शामिल करने के लिए जो AI एजेंट्स का उल्लेख करते हैं, हम इस परिभाषा का उपयोग करेंगे:

AI एजेंट्स बड़े भाषा मॉडल्स (LLMs) को **स्टेट** और **टूल्स** तक पहुंच देकर कार्य करने की अनुमति देते हैं।

![एजेंट मॉडल](../../../translated_images/what-agent.21f2893bdfd01e6a7fd09b0416c2b15594d97f44bbb2ab5a1ff8bf643d2fcb3d.hi.png)

आइए इन शब्दों को परिभाषित करें:

**बड़े भाषा मॉडल्स** - ये वे मॉडल्स हैं जिनका उल्लेख इस पाठ्यक्रम में किया गया है जैसे GPT-3.5, GPT-4, Llama-2, आदि।

**स्टेट** - यह उस संदर्भ को संदर्भित करता है जिसमें LLM काम कर रहा है। LLM अपने पिछले कार्यों और वर्तमान संदर्भ के संदर्भ का उपयोग करता है, जो इसके अगले कार्यों के निर्णय लेने का मार्गदर्शन करता है। AI एजेंट फ्रेमवर्क्स डेवलपर्स को इस संदर्भ को आसानी से बनाए रखने की अनुमति देते हैं।

**टूल्स** - उपयोगकर्ता द्वारा अनुरोधित कार्य को पूरा करने और जिसे LLM ने योजना बनाई है, LLM को टूल्स तक पहुंच की आवश्यकता होती है। टूल्स के कुछ उदाहरण हो सकते हैं: एक डेटाबेस, एक API, एक बाहरी एप्लिकेशन या यहां तक कि एक अन्य LLM!

ये परिभाषाएं आपको आगे बढ़ने के लिए एक अच्छा आधार प्रदान करेंगी क्योंकि हम देखेंगे कि उन्हें कैसे लागू किया जाता है। आइए कुछ अलग-अलग AI एजेंट फ्रेमवर्क्स का अन्वेषण करें:

## LangChain एजेंट्स

[LangChain एजेंट्स](https://python.langchain.com/docs/how_to/#agents?WT.mc_id=academic-105485-koreyst) ऊपर दी गई परिभाषाओं का एक कार्यान्वयन है।

**स्टेट** को प्रबंधित करने के लिए, यह एक अंतर्निहित फ़ंक्शन का उपयोग करता है जिसे `AgentExecutor` कहा जाता है। यह परिभाषित `agent` और उपलब्ध `tools` को स्वीकार करता है।

`Agent Executor` चैट इतिहास को भी संग्रहीत करता है ताकि चैट का संदर्भ प्रदान किया जा सके।

![LangChain एजेंट्स](../../../translated_images/langchain-agents.edcc55b5d5c437169a2037211284154561183c58bcec6d4ac2f8a79046fac9af.hi.png)

LangChain एक [टूल्स का कैटलॉग](https://integrations.langchain.com/tools?WT.mc_id=academic-105485-koreyst) प्रदान करता है जिसे आपके एप्लिकेशन में आयात किया जा सकता है, जिसमें LLM को पहुंच प्राप्त होती है। ये समुदाय और LangChain टीम द्वारा बनाए गए हैं।

आप इन टूल्स को परिभाषित कर सकते हैं और उन्हें `Agent Executor` को पास कर सकते हैं।

दृश्यता AI एजेंट्स के बारे में बात करते समय एक और महत्वपूर्ण पहलू है। एप्लिकेशन डेवलपर्स के लिए यह समझना महत्वपूर्ण है कि LLM कौन सा टूल उपयोग कर रहा है और क्यों। इसके लिए, LangChain टीम ने LangSmith विकसित किया है।

## AutoGen

अगला AI एजेंट फ्रेमवर्क जिसे हम चर्चा करेंगे वह है [AutoGen](https://microsoft.github.io/autogen/?WT.mc_id=academic-105485-koreyst)। AutoGen का मुख्य ध्यान बातचीत पर है। एजेंट्स **बातचीत करने योग्य** और **अनुकूलन योग्य** होते हैं।

**बातचीत करने योग्य -** LLMs एक कार्य को पूरा करने के लिए एक अन्य LLM के साथ बातचीत शुरू कर सकते हैं और जारी रख सकते हैं। यह `AssistantAgents` बनाकर और उन्हें एक विशिष्ट सिस्टम संदेश देकर किया जाता है।

```python

autogen.AssistantAgent( name="Coder", llm_config=llm_config, ) pm = autogen.AssistantAgent( name="Product_manager", system_message="Creative in software product ideas.", llm_config=llm_config, )

```

**अनुकूलन योग्य** - एजेंट्स को केवल LLMs के रूप में ही नहीं बल्कि उपयोगकर्ता या टूल के रूप में भी परिभाषित किया जा सकता है। एक डेवलपर के रूप में, आप एक `UserProxyAgent` परिभाषित कर सकते हैं जो उपयोगकर्ता से प्रतिक्रिया प्राप्त करने के लिए जिम्मेदार होता है ताकि कार्य को पूरा किया जा सके। यह प्रतिक्रिया या तो कार्य के निष्पादन को जारी रख सकती है या इसे रोक सकती है।

```python
user_proxy = UserProxyAgent(name="user_proxy")
```

### स्टेट और टूल्स

स्टेट को बदलने और प्रबंधित करने के लिए, एक सहायक एजेंट कार्य को पूरा करने के लिए Python कोड उत्पन्न करता है।

यहां प्रक्रिया का एक उदाहरण है:

![AutoGen](../../../translated_images/autogen.dee9a25a45fde584fedd84b812a6e31de5a6464687cdb66bb4f2cb7521391856.hi.png)

#### सिस्टम संदेश के साथ परिभाषित LLM

```python
system_message="For weather related tasks, only use the functions you have been provided with. Reply TERMINATE when the task is done."
```

यह सिस्टम संदेश इस विशिष्ट LLM को निर्देशित करता है कि उसके कार्य के लिए कौन से फ़ंक्शन प्रासंगिक हैं। याद रखें, AutoGen के साथ आप विभिन्न सिस्टम संदेशों के साथ कई परिभाषित AssistantAgents रख सकते हैं।

#### उपयोगकर्ता द्वारा चैट शुरू की जाती है

```python
user_proxy.initiate_chat( chatbot, message="I am planning a trip to NYC next week, can you help me pick out what to wear? ", )

```

यह उपयोगकर्ता_प्रॉक्सी (मानव) से संदेश है जो एजेंट की प्रक्रिया को शुरू करेगा कि वह कौन से संभावित फ़ंक्शन को निष्पादित करना चाहिए।

#### फ़ंक्शन निष्पादित किया जाता है

```bash
chatbot (to user_proxy):

***** Suggested tool Call: get_weather ***** Arguments: {"location":"New York City, NY","time_periond:"7","temperature_unit":"Celsius"} ******************************************************** --------------------------------------------------------------------------------

>>>>>>>> EXECUTING FUNCTION get_weather... user_proxy (to chatbot): ***** Response from calling function "get_weather" ***** 112.22727272727272 EUR ****************************************************************

```

एक बार प्रारंभिक चैट संसाधित हो जाने के बाद, एजेंट सुझाए गए टूल को कॉल करने के लिए भेजेगा। इस मामले में, यह एक फ़ंक्शन है जिसे `get_weather` कहा जाता है। आपकी कॉन्फ़िगरेशन के आधार पर, इस फ़ंक्शन को स्वचालित रूप से निष्पादित किया जा सकता है और एजेंट द्वारा पढ़ा जा सकता है या उपयोगकर्ता इनपुट के आधार पर निष्पादित किया जा सकता है।

आप [AutoGen कोड नमूनों](https://microsoft.github.io/autogen/docs/Examples/?WT.mc_id=academic-105485-koreyst) की सूची पा सकते हैं ताकि निर्माण शुरू करने के तरीके का और अधिक अन्वेषण किया जा सके।

## Taskweaver

अगला एजेंट फ्रेमवर्क जिसे हम अन्वेषण करेंगे वह है [Taskweaver](https://microsoft.github.io/TaskWeaver/?WT.mc_id=academic-105485-koreyst)। इसे "कोड-फर्स्ट" एजेंट के रूप में जाना जाता है क्योंकि यह केवल `strings` के साथ काम करने के बजाय Python में DataFrames के साथ काम कर सकता है। यह डेटा विश्लेषण और जनरेशन कार्यों के लिए अत्यधिक उपयोगी हो जाता है। यह ग्राफ और चार्ट बनाने या यादृच्छिक संख्याएं उत्पन्न करने जैसे कार्य हो सकते हैं।

### स्टेट और टूल्स

बातचीत के स्टेट को प्रबंधित करने के लिए, TaskWeaver `Planner` की अवधारणा का उपयोग करता है। `Planner` एक LLM है जो उपयोगकर्ताओं से अनुरोध लेता है और इस अनुरोध को पूरा करने के लिए आवश्यक कार्यों को मैप करता है।

कार्य को पूरा करने के लिए `Planner` टूल्स के संग्रह को एक्सेस करता है जिसे `Plugins` कहा जाता है। यह Python क्लासेस या एक सामान्य कोड इंटरप्रेटर हो सकता है। ये प्लगइन्स एम्बेडिंग के रूप में संग्रहीत होते हैं ताकि LLM सही प्लगइन को बेहतर तरीके से खोज सके।

![Taskweaver](../../../translated_images/taskweaver.da8559999267715a95b7677cf9b7d7dd8420aee6f3c484ced1833f081988dcd5.hi.png)

यहां एक प्लगइन का उदाहरण है जो विसंगति का पता लगाने को संभालता है:

```python
class AnomalyDetectionPlugin(Plugin): def __call__(self, df: pd.DataFrame, time_col_name: str, value_col_name: str):
```

कोड को निष्पादित करने से पहले सत्यापित किया जाता है। Taskweaver में संदर्भ को प्रबंधित करने के लिए एक और सुविधा `experience` है। अनुभव बातचीत के संदर्भ को लंबे समय तक YAML फ़ाइल में संग्रहीत करने की अनुमति देता है। इसे इस तरह से कॉन्फ़िगर किया जा सकता है कि LLM समय के साथ कुछ कार्यों पर सुधार करता है क्योंकि इसे पिछले वार्तालापों के संपर्क में लाया जाता है।

## JARVIS

अंतिम एजेंट फ्रेमवर्क जिसे हम अन्वेषण करेंगे वह है [JARVIS](https://github.com/microsoft/JARVIS?tab=readme-ov-file?WT.mc_id=academic-105485-koreyst)। JARVIS को अनोखा बनाता है कि यह बातचीत के `state` को प्रबंधित करने के लिए एक LLM का उपयोग करता है और `tools` अन्य AI मॉडल्स होते हैं। प्रत्येक AI मॉडल विशेष कार्यों को करने वाले मॉडल्स होते हैं जैसे ऑब्जेक्ट डिटेक्शन, ट्रांसक्रिप्शन या इमेज कैप्शनिंग।

![JARVIS](../../../translated_images/jarvis.762ddbadbd1a3a3364d4ca3db1a7a9c0d2180060c0f8da6f7bd5b5ea2a115aa7.hi.png)

LLM, एक सामान्य उद्देश्य मॉडल होने के नाते, उपयोगकर्ता से अनुरोध प्राप्त करता है और विशिष्ट कार्य और इसे पूरा करने के लिए आवश्यक किसी भी तर्क/डेटा की पहचान करता है।

```python
[{"task": "object-detection", "id": 0, "dep": [-1], "args": {"image": "e1.jpg" }}]
```

LLM फिर अनुरोध को इस तरह से प्रारूपित करता है कि विशेष AI मॉडल इसे समझ सके, जैसे JSON। एक बार जब AI मॉडल ने कार्य के आधार पर अपनी भविष्यवाणी वापस कर दी, तो LLM प्रतिक्रिया प्राप्त करता है।

यदि कार्य को पूरा करने के लिए कई मॉडल्स की आवश्यकता होती है, तो यह उन मॉडल्स से प्रतिक्रिया की व्याख्या भी करेगा और उन्हें एक साथ लाकर उपयोगकर्ता को प्रतिक्रिया उत्पन्न करेगा।

नीचे दिए गए उदाहरण में दिखाया गया है कि यह कैसे काम करेगा जब उपयोगकर्ता एक तस्वीर में वस्तुओं का विवरण और संख्या मांग रहा हो:

## असाइनमेंट

AI एजेंट्स के बारे में अपनी सीख को जारी रखने के लिए आप AutoGen के साथ निर्माण कर सकते हैं:

- एक एप्लिकेशन जो एक शिक्षा स्टार्टअप के विभिन्न विभागों के साथ एक व्यावसायिक बैठक का अनुकरण करता है।
- सिस्टम संदेश बनाएं जो LLMs को विभिन्न व्यक्तित्वों और प्राथमिकताओं को समझने में मार्गदर्शन करें, और उपयोगकर्ता को एक नए उत्पाद विचार को प्रस्तुत करने में सक्षम बनाएं।
- LLM को फिर प्रत्येक विभाग से अनुवर्ती प्रश्न उत्पन्न करने चाहिए ताकि पिच और उत्पाद विचार को परिष्कृत और सुधार किया जा सके।

## सीखना यहीं समाप्त नहीं होता, यात्रा जारी रखें

इस पाठ को पूरा करने के बाद, हमारे [Generative AI Learning संग्रह](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) को देखें ताकि आप अपनी जनरेटिव AI ज्ञान को और बढ़ा सकें!

---

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में दस्तावेज़ को आधिकारिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।