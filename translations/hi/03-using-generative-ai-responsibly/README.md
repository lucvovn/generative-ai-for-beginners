<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4d57fad773cbeb69c5dd62e65c34200d",
  "translation_date": "2025-10-18T00:12:36+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "hi"
}
-->
# जिम्मेदारी से जनरेटिव एआई का उपयोग करना

[![जिम्मेदारी से जनरेटिव एआई का उपयोग करना](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.hi.png)](https://youtu.be/YOp-e1GjZdA?si=7Wv4wu3x44L1DCVj)

> _ऊपर दी गई छवि पर क्लिक करें इस पाठ का वीडियो देखने के लिए_

एआई, विशेष रूप से जनरेटिव एआई, के प्रति आकर्षित होना आसान है, लेकिन आपको यह विचार करना होगा कि आप इसका जिम्मेदारी से उपयोग कैसे करेंगे। आपको यह सुनिश्चित करने के तरीकों पर विचार करना होगा कि इसका आउटपुट निष्पक्ष, हानिरहित और अधिक हो। यह अध्याय आपको इस संदर्भ, विचार करने योग्य बातों और आपके एआई उपयोग को बेहतर बनाने के लिए सक्रिय कदम उठाने के तरीकों को प्रदान करने का उद्देश्य रखता है।

## परिचय

इस पाठ में शामिल होगा:

- जनरेटिव एआई एप्लिकेशन बनाते समय जिम्मेदार एआई को प्राथमिकता क्यों देनी चाहिए।
- जिम्मेदार एआई के मुख्य सिद्धांत और वे जनरेटिव एआई से कैसे संबंधित हैं।
- रणनीति और उपकरणों के माध्यम से इन जिम्मेदार एआई सिद्धांतों को व्यवहार में कैसे लाया जाए।

## सीखने के लक्ष्य

इस पाठ को पूरा करने के बाद आप जानेंगे:

- जनरेटिव एआई एप्लिकेशन बनाते समय जिम्मेदार एआई का महत्व।
- जनरेटिव एआई एप्लिकेशन बनाते समय जिम्मेदार एआई के मुख्य सिद्धांतों को कब सोचना और लागू करना चाहिए।
- जिम्मेदार एआई की अवधारणा को व्यवहार में लाने के लिए आपके पास कौन-कौन से उपकरण और रणनीतियां उपलब्ध हैं।

## जिम्मेदार एआई के सिद्धांत

जनरेटिव एआई का उत्साह पहले से कहीं अधिक है। इस उत्साह ने इस क्षेत्र में कई नए डेवलपर्स, ध्यान और फंडिंग को आकर्षित किया है। जबकि यह जनरेटिव एआई का उपयोग करके उत्पाद और कंपनियां बनाने के इच्छुक किसी भी व्यक्ति के लिए बहुत सकारात्मक है, यह भी महत्वपूर्ण है कि हम जिम्मेदारी से आगे बढ़ें।

इस पाठ्यक्रम के दौरान, हम अपने स्टार्टअप और हमारे एआई शिक्षा उत्पाद को बनाने पर ध्यान केंद्रित कर रहे हैं। हम जिम्मेदार एआई के सिद्धांतों का उपयोग करेंगे: निष्पक्षता, समावेशिता, विश्वसनीयता/सुरक्षा, सुरक्षा और गोपनीयता, पारदर्शिता और जवाबदेही। इन सिद्धांतों के साथ, हम यह पता लगाएंगे कि वे हमारे उत्पादों में जनरेटिव एआई के उपयोग से कैसे संबंधित हैं।

## जिम्मेदार एआई को प्राथमिकता क्यों दें

जब आप कोई उत्पाद बना रहे हों, तो उपयोगकर्ता के सर्वोत्तम हित को ध्यान में रखते हुए मानव-केंद्रित दृष्टिकोण अपनाने से सर्वोत्तम परिणाम मिलते हैं।

जनरेटिव एआई की विशिष्टता इसकी उपयोगकर्ताओं के लिए सहायक उत्तर, जानकारी, मार्गदर्शन और सामग्री बनाने की शक्ति है। यह बिना कई मैनुअल चरणों के किया जा सकता है, जो बहुत प्रभावशाली परिणाम दे सकता है। उचित योजना और रणनीतियों के बिना, यह दुर्भाग्यवश आपके उपयोगकर्ताओं, आपके उत्पाद और पूरे समाज के लिए कुछ हानिकारक परिणाम भी दे सकता है।

आइए इनमें से कुछ (लेकिन सभी नहीं) संभावित हानिकारक परिणामों पर नज़र डालें:

### भ्रम

भ्रम एक शब्द है जिसका उपयोग तब किया जाता है जब एक LLM ऐसा कंटेंट उत्पन्न करता है जो या तो पूरी तरह से बेतुका होता है या कुछ ऐसा होता है जिसे हम अन्य जानकारी स्रोतों के आधार पर तथ्यात्मक रूप से गलत मानते हैं।

मान लीजिए कि हम अपने स्टार्टअप के लिए एक फीचर बनाते हैं जो छात्रों को मॉडल से ऐतिहासिक प्रश्न पूछने की अनुमति देता है। एक छात्र सवाल पूछता है `टाइटैनिक का एकमात्र जीवित व्यक्ति कौन था?`

मॉडल नीचे दिए गए उत्तर जैसा कुछ उत्पन्न करता है:

![प्रॉम्प्ट कहता है "टाइटैनिक का एकमात्र जीवित व्यक्ति कौन था"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(स्रोत: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

यह एक बहुत ही आत्मविश्वासपूर्ण और विस्तृत उत्तर है। दुर्भाग्यवश, यह गलत है। न्यूनतम शोध के साथ भी, कोई यह पता लगा सकता है कि टाइटैनिक आपदा के एक से अधिक जीवित व्यक्ति थे। एक छात्र जो इस विषय पर शोध करना शुरू कर रहा है, उसके लिए यह उत्तर इतना प्रभावशाली हो सकता है कि इसे सवाल न किया जाए और इसे तथ्य के रूप में माना जाए। इसके परिणामस्वरूप एआई सिस्टम अविश्वसनीय हो सकता है और हमारे स्टार्टअप की प्रतिष्ठा पर नकारात्मक प्रभाव पड़ सकता है।

किसी भी दिए गए LLM के प्रत्येक पुनरावृत्ति के साथ, हमने भ्रम को कम करने के आसपास प्रदर्शन सुधार देखा है। इस सुधार के बावजूद, हमें एप्लिकेशन बिल्डर और उपयोगकर्ता के रूप में इन सीमाओं के प्रति जागरूक रहना चाहिए।

### हानिकारक सामग्री

हमने पहले के खंड में कवर किया जब एक LLM गलत या बेतुके उत्तर उत्पन्न करता है। एक और जोखिम जिसे हमें जानना चाहिए वह है जब एक मॉडल हानिकारक सामग्री के साथ प्रतिक्रिया करता है।

हानिकारक सामग्री को निम्नलिखित रूप में परिभाषित किया जा सकता है:

- आत्म-हानि या कुछ समूहों को नुकसान पहुंचाने के निर्देश देना या प्रोत्साहित करना।
- घृणास्पद या अपमानजनक सामग्री।
- किसी भी प्रकार के हमले या हिंसक कृत्यों की योजना बनाने का मार्गदर्शन।
- अवैध सामग्री खोजने या अवैध कृत्यों को अंजाम देने के निर्देश देना।
- यौन स्पष्ट सामग्री प्रदर्शित करना।

हमारे स्टार्टअप के लिए, हम यह सुनिश्चित करना चाहते हैं कि हमारे पास सही उपकरण और रणनीतियां हों ताकि इस प्रकार की सामग्री छात्रों को दिखाई न दे।

### निष्पक्षता की कमी

निष्पक्षता को "सुनिश्चित करना कि एआई सिस्टम पूर्वाग्रह और भेदभाव से मुक्त है और वे सभी के साथ निष्पक्ष और समान व्यवहार करते हैं" के रूप में परिभाषित किया गया है। जनरेटिव एआई की दुनिया में, हम यह सुनिश्चित करना चाहते हैं कि हाशिए पर पड़े समूहों के बहिष्कृत दृष्टिकोण मॉडल के आउटपुट द्वारा सुदृढ़ न हों।

इस प्रकार के आउटपुट न केवल हमारे उपयोगकर्ताओं के लिए सकारात्मक उत्पाद अनुभव बनाने के लिए विनाशकारी हैं, बल्कि वे आगे सामाजिक नुकसान भी पहुंचाते हैं। एप्लिकेशन बिल्डर के रूप में, हमें हमेशा जनरेटिव एआई के साथ समाधान बनाते समय एक व्यापक और विविध उपयोगकर्ता आधार को ध्यान में रखना चाहिए।

## जिम्मेदारी से जनरेटिव एआई का उपयोग कैसे करें

अब जब हमने जिम्मेदार जनरेटिव एआई के महत्व की पहचान कर ली है, तो आइए देखें कि हम अपने एआई समाधान को जिम्मेदारी से बनाने के लिए 4 कदम कैसे उठा सकते हैं:

![मिटिगेट साइकिल](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.hi.png)

### संभावित नुकसान को मापें

सॉफ़्टवेयर परीक्षण में, हम एप्लिकेशन पर उपयोगकर्ता की अपेक्षित क्रियाओं का परीक्षण करते हैं। इसी तरह, उपयोगकर्ताओं द्वारा सबसे अधिक उपयोग किए जाने वाले प्रॉम्प्ट के विविध सेट का परीक्षण करना संभावित नुकसान को मापने का एक अच्छा तरीका है।

चूंकि हमारा स्टार्टअप एक शिक्षा उत्पाद बना रहा है, यह शिक्षा से संबंधित प्रॉम्प्ट की एक सूची तैयार करना अच्छा होगा। यह किसी विशेष विषय, ऐतिहासिक तथ्यों और छात्र जीवन के बारे में प्रॉम्प्ट को कवर कर सकता है।

### संभावित नुकसान को कम करें

अब यह पता लगाने का समय है कि हम मॉडल और इसकी प्रतिक्रियाओं के कारण होने वाले संभावित नुकसान को कैसे रोक सकते हैं या सीमित कर सकते हैं। हम इसे 4 अलग-अलग स्तरों में देख सकते हैं:

![मिटिगेशन लेयर्स](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.hi.png)

- **मॉडल**। सही उपयोग केस के लिए सही मॉडल चुनना। GPT-4 जैसे बड़े और अधिक जटिल मॉडल छोटे और अधिक विशिष्ट उपयोग मामलों में लागू होने पर हानिकारक सामग्री का अधिक जोखिम पैदा कर सकते हैं। अपने प्रशिक्षण डेटा का उपयोग करके फाइन-ट्यूनिंग भी हानिकारक सामग्री के जोखिम को कम करता है।

- **सुरक्षा प्रणाली**। सुरक्षा प्रणाली मॉडल की सेवा करने वाले प्लेटफ़ॉर्म पर उपकरणों और कॉन्फ़िगरेशन का एक सेट है जो नुकसान को कम करने में मदद करता है। इसका एक उदाहरण Azure OpenAI सेवा पर सामग्री फ़िल्टरिंग प्रणाली है। सिस्टम को जेलब्रेक हमलों और बॉट्स से अनुरोध जैसी अवांछित गतिविधि का पता लगाना चाहिए।

- **मेटाप्रॉम्प्ट**। मेटाप्रॉम्प्ट और ग्राउंडिंग ऐसे तरीके हैं जिनसे हम मॉडल को कुछ व्यवहारों और जानकारी के आधार पर निर्देशित या सीमित कर सकते हैं। यह मॉडल की कुछ सीमाओं को परिभाषित करने के लिए सिस्टम इनपुट का उपयोग कर सकता है। इसके अलावा, ऐसे आउटपुट प्रदान करना जो सिस्टम के दायरे या डोमेन के लिए अधिक प्रासंगिक हों।

यह केवल विश्वसनीय स्रोतों के चयन से जानकारी प्राप्त करने के लिए मॉडल को प्राप्त करने के लिए रिट्रीवल ऑगमेंटेड जनरेशन (RAG) जैसी तकनीकों का उपयोग करना भी हो सकता है। इस पाठ्यक्रम में [सर्च एप्लिकेशन बनाना](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst) पर एक पाठ बाद में है।

- **उपयोगकर्ता अनुभव**। अंतिम स्तर वह है जहां उपयोगकर्ता सीधे हमारे एप्लिकेशन के इंटरफ़ेस के माध्यम से मॉडल के साथ बातचीत करता है। इस तरह हम UI/UX को डिज़ाइन कर सकते हैं ताकि उपयोगकर्ता को उन प्रकार के इनपुट पर सीमित किया जा सके जो वे मॉडल को भेज सकते हैं और साथ ही उपयोगकर्ता को प्रदर्शित किए गए टेक्स्ट या छवियां। एआई एप्लिकेशन को तैनात करते समय, हमें यह भी पारदर्शी होना चाहिए कि हमारा जनरेटिव एआई एप्लिकेशन क्या कर सकता है और क्या नहीं कर सकता।

हमारे पास [एआई एप्लिकेशन के लिए UX डिज़ाइन करना](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst) पर एक पूरा पाठ समर्पित है।

- **मॉडल का मूल्यांकन करें**। LLMs के साथ काम करना चुनौतीपूर्ण हो सकता है क्योंकि हमें हमेशा उस डेटा पर नियंत्रण नहीं होता है जिस पर मॉडल को प्रशिक्षित किया गया था। फिर भी, हमें हमेशा मॉडल के प्रदर्शन और आउटपुट का मूल्यांकन करना चाहिए। मॉडल की सटीकता, समानता, ग्राउंडेडनेस और आउटपुट की प्रासंगिकता को मापना अभी भी महत्वपूर्ण है। यह हितधारकों और उपयोगकर्ताओं को पारदर्शिता और विश्वास प्रदान करने में मदद करता है।

### जिम्मेदार जनरेटिव एआई समाधान संचालित करें

अपने एआई एप्लिकेशन के आसपास एक परिचालन अभ्यास बनाना अंतिम चरण है। इसमें कानूनी और सुरक्षा जैसे हमारे स्टार्टअप के अन्य हिस्सों के साथ साझेदारी करना शामिल है ताकि यह सुनिश्चित किया जा सके कि हम सभी नियामक नीतियों का पालन कर रहे हैं। लॉन्च करने से पहले, हम डिलीवरी, घटनाओं को संभालने और रोलबैक के आसपास योजनाएं बनाना चाहते हैं ताकि हमारे उपयोगकर्ताओं को किसी भी नुकसान से बचाया जा सके।

## उपकरण

जिम्मेदार एआई समाधान विकसित करने का कार्य भले ही बहुत अधिक लग सकता है, लेकिन यह प्रयास के लायक है। जैसे-जैसे जनरेटिव एआई का क्षेत्र बढ़ता है, डेवलपर्स को अपनी वर्कफ़्लो में जिम्मेदारी को कुशलतापूर्वक एकीकृत करने में मदद करने के लिए अधिक उपकरण परिपक्व होंगे। उदाहरण के लिए, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) एपीआई अनुरोध के माध्यम से हानिकारक सामग्री और छवियों का पता लगाने में मदद कर सकता है।

## ज्ञान जांच

जिम्मेदार एआई उपयोग सुनिश्चित करने के लिए आपको किन बातों का ध्यान रखना चाहिए?

1. कि उत्तर सही है।
1. हानिकारक उपयोग, कि एआई का आपराधिक उद्देश्यों के लिए उपयोग न हो।
1. यह सुनिश्चित करना कि एआई पूर्वाग्रह और भेदभाव से मुक्त है।

उत्तर: 2 और 3 सही हैं। जिम्मेदार एआई आपको हानिकारक प्रभावों और पूर्वाग्रहों को कम करने और अधिक विचार करने में मदद करता है।

## 🚀 चुनौती

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) के बारे में पढ़ें और देखें कि आप अपने उपयोग के लिए क्या अपनाना चाहते हैं।

## शानदार काम, अपनी सीख जारी रखें

इस पाठ को पूरा करने के बाद, हमारे [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) को देखें ताकि आप जनरेटिव एआई के ज्ञान को और बढ़ा सकें!

पाठ 4 पर जाएं जहां हम [प्रॉम्प्ट इंजीनियरिंग के मूलभूत सिद्धांतों](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst) को देखेंगे!

---

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में दस्तावेज़ को आधिकारिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम जिम्मेदार नहीं हैं।