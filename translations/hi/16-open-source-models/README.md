<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a2a83aac52158c23161046cbd13faa2b",
  "translation_date": "2025-10-18T00:20:02+00:00",
  "source_file": "16-open-source-models/README.md",
  "language_code": "hi"
}
-->
[![ओपन सोर्स मॉडल्स](../../../translated_images/16-lesson-banner.6b56555e8404fda1716382db4832cecbe616ccd764de381f0af6cfd694d05f74.hi.png)](https://youtu.be/CuICgfuHFSg?si=x8SpFRUsIxM9dohN)

## परिचय

ओपन-सोर्स LLMs की दुनिया रोमांचक और लगातार विकसित हो रही है। यह पाठ ओपन सोर्स मॉडल्स पर गहराई से जानकारी प्रदान करने का उद्देश्य रखता है। यदि आप जानना चाहते हैं कि मालिकाना मॉडल्स की तुलना में ओपन सोर्स मॉडल्स कैसे हैं, तो ["विभिन्न LLMs का अन्वेषण और तुलना" पाठ](../02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst) पर जाएं। यह पाठ फाइन-ट्यूनिंग के विषय को भी कवर करेगा, लेकिन इसका अधिक विस्तृत विवरण ["फाइन-ट्यूनिंग LLMs" पाठ](../18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst) में पाया जा सकता है।

## सीखने के लक्ष्य

- ओपन सोर्स मॉडल्स की समझ प्राप्त करना
- ओपन सोर्स मॉडल्स के साथ काम करने के लाभों को समझना
- Hugging Face और Azure AI Studio पर उपलब्ध ओपन मॉडल्स का अन्वेषण करना

## ओपन सोर्स मॉडल्स क्या हैं?

ओपन सोर्स सॉफ़्टवेयर ने विभिन्न क्षेत्रों में प्रौद्योगिकी के विकास में महत्वपूर्ण भूमिका निभाई है। ओपन सोर्स इनिशिएटिव (OSI) ने सॉफ़्टवेयर को ओपन सोर्स के रूप में वर्गीकृत करने के लिए [10 मानदंड](https://web.archive.org/web/20241126001143/https://opensource.org/osd?WT.mc_id=academic-105485-koreyst) परिभाषित किए हैं। स्रोत कोड को OSI द्वारा अनुमोदित लाइसेंस के तहत खुले तौर पर साझा किया जाना चाहिए।

हालांकि LLMs का विकास सॉफ़्टवेयर विकसित करने के समान तत्वों को साझा करता है, लेकिन प्रक्रिया बिल्कुल समान नहीं है। इसने LLMs के संदर्भ में ओपन सोर्स की परिभाषा पर समुदाय में बहुत चर्चा की है। एक मॉडल को पारंपरिक ओपन सोर्स परिभाषा के साथ संरेखित करने के लिए निम्नलिखित जानकारी सार्वजनिक रूप से उपलब्ध होनी चाहिए:

- मॉडल को प्रशिक्षित करने के लिए उपयोग किए गए डेटा सेट।
- प्रशिक्षण के हिस्से के रूप में पूर्ण मॉडल वेट्स।
- मूल्यांकन कोड।
- फाइन-ट्यूनिंग कोड।
- पूर्ण मॉडल वेट्स और प्रशिक्षण मेट्रिक्स।

वर्तमान में केवल कुछ ही मॉडल्स हैं जो इन मानदंडों को पूरा करते हैं। [Allen Institute for Artificial Intelligence (AllenAI) द्वारा बनाया गया OLMo मॉडल](https://huggingface.co/allenai/OLMo-7B?WT.mc_id=academic-105485-koreyst) इस श्रेणी में फिट बैठता है।

इस पाठ के लिए, हम इन मॉडल्स को "ओपन मॉडल्स" कहेंगे क्योंकि वे लेखन के समय ऊपर दिए गए मानदंडों से मेल नहीं खा सकते हैं।

## ओपन मॉडल्स के लाभ

**अत्यधिक अनुकूलन योग्य** - चूंकि ओपन मॉडल्स विस्तृत प्रशिक्षण जानकारी के साथ जारी किए जाते हैं, शोधकर्ता और डेवलपर्स मॉडल के आंतरिक हिस्सों को संशोधित कर सकते हैं। यह अत्यधिक विशिष्ट मॉडल्स बनाने में सक्षम बनाता है जो किसी विशेष कार्य या अध्ययन क्षेत्र के लिए फाइन-ट्यून किए गए हैं। इसके कुछ उदाहरण हैं कोड जनरेशन, गणितीय संचालन और जीवविज्ञान।

**लागत** - इन मॉडल्स का उपयोग और तैनाती करने की प्रति टोकन लागत मालिकाना मॉडल्स की तुलना में कम होती है। जब जनरेटिव AI एप्लिकेशन बनाते हैं, तो प्रदर्शन बनाम कीमत को अपने उपयोग के मामले में काम करते समय देखना चाहिए।

![मॉडल लागत](../../../translated_images/model-price.3f5a3e4d32ae00b465325159e1f4ebe7b5861e95117518c6bfc37fe842950687.hi.png)  
स्रोत: आर्टिफिशियल एनालिसिस

**लचीलापन** - ओपन मॉडल्स के साथ काम करने से विभिन्न मॉडल्स का उपयोग करने या उन्हें संयोजित करने में लचीलापन मिलता है। इसका एक उदाहरण [HuggingChat Assistants](https://huggingface.co/chat?WT.mc_id=academic-105485-koreyst) है, जहां उपयोगकर्ता सीधे उपयोगकर्ता इंटरफ़ेस में उपयोग किए जा रहे मॉडल का चयन कर सकते हैं:

![मॉडल चुनें](../../../translated_images/choose-model.f095d15bbac922141591fd4fac586dc8d25e69b42abf305d441b84c238e293f2.hi.png)

## विभिन्न ओपन मॉडल्स का अन्वेषण

### Llama 2

[LLama2](https://huggingface.co/meta-llama?WT.mc_id=academic-105485-koreyst), Meta द्वारा विकसित, एक ओपन मॉडल है जो चैट आधारित एप्लिकेशन के लिए अनुकूलित है। यह इसके फाइन-ट्यूनिंग विधि के कारण है, जिसमें बड़ी मात्रा में संवाद और मानव प्रतिक्रिया शामिल है। इस विधि के साथ, मॉडल अधिक परिणाम उत्पन्न करता है जो मानव अपेक्षाओं के अनुरूप होते हैं और बेहतर उपयोगकर्ता अनुभव प्रदान करते हैं।

Llama के कुछ फाइन-ट्यून किए गए संस्करणों में [Japanese Llama](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b?WT.mc_id=academic-105485-koreyst) शामिल है, जो जापानी में विशेषज्ञता रखता है और [Llama Pro](https://huggingface.co/TencentARC/LLaMA-Pro-8B?WT.mc_id=academic-105485-koreyst), जो बेस मॉडल का एक उन्नत संस्करण है।

### Mistral

[Mistral](https://huggingface.co/mistralai?WT.mc_id=academic-105485-koreyst) एक ओपन मॉडल है जो उच्च प्रदर्शन और दक्षता पर केंद्रित है। यह Mixture-of-Experts दृष्टिकोण का उपयोग करता है जो एक समूह के विशेषज्ञ मॉडल्स को एक प्रणाली में जोड़ता है, जहां इनपुट के आधार पर, कुछ मॉडल्स का चयन किया जाता है। यह गणना को अधिक प्रभावी बनाता है क्योंकि मॉडल्स केवल उन इनपुट्स को संबोधित करते हैं जिनमें वे विशेषज्ञ हैं।

Mistral के कुछ फाइन-ट्यून किए गए संस्करणों में [BioMistral](https://huggingface.co/BioMistral/BioMistral-7B?text=Mon+nom+est+Thomas+et+mon+principal?WT.mc_id=academic-105485-koreyst) शामिल है, जो चिकित्सा क्षेत्र पर केंद्रित है और [OpenMath Mistral](https://huggingface.co/nvidia/OpenMath-Mistral-7B-v0.1-hf?WT.mc_id=academic-105485-koreyst), जो गणितीय गणना करता है।

### Falcon

[Falcon](https://huggingface.co/tiiuae?WT.mc_id=academic-105485-koreyst) एक LLM है जिसे Technology Innovation Institute (**TII**) द्वारा बनाया गया है। Falcon-40B को 40 बिलियन पैरामीटर्स पर प्रशिक्षित किया गया था, जो कम कंप्यूट बजट के साथ GPT-3 से बेहतर प्रदर्शन करता है। यह FlashAttention एल्गोरिदम और मल्टीक्वेरी अटेंशन का उपयोग करता है जो इसे अनुमान समय पर मेमोरी आवश्यकताओं को कम करने में सक्षम बनाता है। इस कम अनुमान समय के साथ, Falcon-40B चैट एप्लिकेशन के लिए उपयुक्त है।

Falcon के कुछ फाइन-ट्यून किए गए संस्करणों में [OpenAssistant](https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560?WT.mc_id=academic-105485-koreyst) शामिल है, जो ओपन मॉडल्स पर आधारित एक सहायक है और [GPT4ALL](https://huggingface.co/nomic-ai/gpt4all-falcon?WT.mc_id=academic-105485-koreyst), जो बेस मॉडल से बेहतर प्रदर्शन करता है।

## कैसे चुनें

ओपन मॉडल चुनने के लिए कोई एक उत्तर नहीं है। एक अच्छा तरीका Azure AI Studio के टास्क फीचर द्वारा फ़िल्टर का उपयोग करना है। यह आपको यह समझने में मदद करेगा कि मॉडल को किस प्रकार के कार्यों के लिए प्रशिक्षित किया गया है। Hugging Face भी एक LLM लीडरबोर्ड बनाए रखता है जो आपको कुछ मेट्रिक्स के आधार पर सबसे अच्छा प्रदर्शन करने वाले मॉडल्स दिखाता है।

विभिन्न प्रकारों में LLMs की तुलना करने के लिए [Artificial Analysis](https://artificialanalysis.ai/?WT.mc_id=academic-105485-koreyst) एक और शानदार संसाधन है:

![मॉडल गुणवत्ता](../../../translated_images/model-quality.aaae1c22e00f7ee1cd9dc186c611ac6ca6627eabd19e5364dce9e216d25ae8a5.hi.png)  
स्रोत: आर्टिफिशियल एनालिसिस

यदि आप किसी विशेष उपयोग के मामले पर काम कर रहे हैं, तो उसी क्षेत्र पर केंद्रित फाइन-ट्यून किए गए संस्करणों की खोज करना प्रभावी हो सकता है। अपने और अपने उपयोगकर्ताओं की अपेक्षाओं के अनुसार प्रदर्शन देखने के लिए कई ओपन मॉडल्स के साथ प्रयोग करना एक और अच्छा अभ्यास है।

## अगले कदम

ओपन मॉडल्स के बारे में सबसे अच्छी बात यह है कि आप उनके साथ काम करना जल्दी शुरू कर सकते हैं। [Azure AI Foundry Model Catalog](https://ai.azure.com?WT.mc_id=academic-105485-koreyst) देखें, जिसमें Hugging Face संग्रह की विशेषता है जिसमें यहां चर्चा किए गए मॉडल्स शामिल हैं।

## सीखना यहीं समाप्त नहीं होता, यात्रा जारी रखें

इस पाठ को पूरा करने के बाद, हमारे [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) को देखें ताकि आप अपनी जनरेटिव AI ज्ञान को और बढ़ा सकें!

---

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में दस्तावेज़ को आधिकारिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।