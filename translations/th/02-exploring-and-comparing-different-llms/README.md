<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b7629b8ee4d7d874a27213e903d86a7",
  "translation_date": "2025-10-17T18:37:40+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "th"
}
-->
# การสำรวจและเปรียบเทียบ LLMs ต่างๆ

[![การสำรวจและเปรียบเทียบ LLMs ต่างๆ](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.th.png)](https://youtu.be/KIRUeDKscfI?si=8BHX1zvwzQBn-PlK)

> _คลิกที่ภาพด้านบนเพื่อดูวิดีโอของบทเรียนนี้_

ในบทเรียนก่อนหน้านี้ เราได้เห็นว่า Generative AI กำลังเปลี่ยนแปลงภูมิทัศน์ของเทคโนโลยีอย่างไร วิธีการทำงานของ Large Language Models (LLMs) และวิธีที่ธุรกิจ เช่น สตาร์ทอัพของเรา สามารถนำไปใช้กับกรณีการใช้งานและเติบโตได้! ในบทนี้ เราจะเปรียบเทียบและวิเคราะห์ LLMs ประเภทต่างๆ เพื่อทำความเข้าใจข้อดีและข้อเสียของแต่ละแบบ

ขั้นตอนต่อไปในเส้นทางของสตาร์ทอัพของเราคือการสำรวจภูมิทัศน์ปัจจุบันของ LLMs และทำความเข้าใจว่าแบบใดเหมาะสมกับกรณีการใช้งานของเรา

## บทนำ

บทเรียนนี้จะครอบคลุม:

- ประเภทต่างๆ ของ LLMs ในภูมิทัศน์ปัจจุบัน
- การทดสอบ การปรับปรุง และการเปรียบเทียบโมเดลต่างๆ สำหรับกรณีการใช้งานของคุณใน Azure
- วิธีการปรับใช้ LLM

## เป้าหมายการเรียนรู้

หลังจากจบบทเรียนนี้ คุณจะสามารถ:

- เลือกโมเดลที่เหมาะสมสำหรับกรณีการใช้งานของคุณ
- เข้าใจวิธีการทดสอบ ปรับปรุง และเพิ่มประสิทธิภาพของโมเดลของคุณ
- รู้วิธีที่ธุรกิจปรับใช้โมเดล

## ทำความเข้าใจประเภทต่างๆ ของ LLMs

LLMs สามารถแบ่งประเภทได้หลายแบบตามสถาปัตยกรรม ข้อมูลการฝึก และกรณีการใช้งาน การทำความเข้าใจความแตกต่างเหล่านี้จะช่วยให้สตาร์ทอัพของเราเลือกโมเดลที่เหมาะสมกับสถานการณ์ และเข้าใจวิธีการทดสอบ ปรับปรุง และเพิ่มประสิทธิภาพ

มีโมเดล LLMs หลายประเภท การเลือกโมเดลขึ้นอยู่กับสิ่งที่คุณต้องการใช้ ข้อมูลของคุณ งบประมาณ และอื่นๆ

ขึ้นอยู่กับว่าคุณต้องการใช้โมเดลสำหรับการสร้างข้อความ เสียง วิดีโอ ภาพ และอื่นๆ คุณอาจเลือกใช้โมเดลประเภทต่างๆ

- **การรู้จำเสียงและคำพูด** สำหรับวัตถุประสงค์นี้ โมเดลประเภท Whisper เป็นตัวเลือกที่ดี เนื่องจากเป็นโมเดลทั่วไปที่มุ่งเน้นการรู้จำคำพูด มันถูกฝึกด้วยเสียงที่หลากหลายและสามารถทำการรู้จำคำพูดหลายภาษาได้ เรียนรู้เพิ่มเติมเกี่ยวกับ [โมเดลประเภท Whisper ที่นี่](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst)

- **การสร้างภาพ** สำหรับการสร้างภาพ DALL-E และ Midjourney เป็นตัวเลือกที่รู้จักกันดี DALL-E มีให้บริการผ่าน Azure OpenAI [อ่านเพิ่มเติมเกี่ยวกับ DALL-E ที่นี่](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) และในบทที่ 9 ของหลักสูตรนี้

- **การสร้างข้อความ** โมเดลส่วนใหญ่ถูกฝึกเพื่อการสร้างข้อความ และคุณมีตัวเลือกมากมายตั้งแต่ GPT-3.5 ถึง GPT-4 ซึ่งมีค่าใช้จ่ายต่างกัน โดย GPT-4 มีราคาสูงที่สุด ควรลองดู [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) เพื่อประเมินว่าโมเดลใดเหมาะสมที่สุดสำหรับความต้องการของคุณในแง่ของความสามารถและค่าใช้จ่าย

- **การทำงานหลายรูปแบบ** หากคุณต้องการจัดการข้อมูลหลายประเภทในอินพุตและเอาต์พุต คุณอาจต้องการดูโมเดลอย่าง [gpt-4 turbo with vision หรือ gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) ซึ่งเป็นรุ่นล่าสุดของโมเดล OpenAI ที่สามารถรวมการประมวลผลภาษาธรรมชาติกับการเข้าใจภาพ ทำให้สามารถโต้ตอบผ่านอินเทอร์เฟซหลายรูปแบบได้

การเลือกโมเดลหมายความว่าคุณจะได้รับความสามารถพื้นฐาน ซึ่งอาจยังไม่เพียงพอ อย่างไรก็ตาม บ่อยครั้งคุณมีข้อมูลเฉพาะของบริษัทที่คุณต้องบอก LLMs ด้วย มีวิธีการหลายแบบในการจัดการเรื่องนี้ ซึ่งจะกล่าวถึงในส่วนถัดไป

### Foundation Models กับ LLMs

คำว่า Foundation Model ถูก [บัญญัติโดยนักวิจัยจาก Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) และถูกนิยามว่าเป็นโมเดล AI ที่มีเกณฑ์บางอย่าง เช่น:

- **ถูกฝึกด้วยการเรียนรู้แบบไม่มีผู้ดูแลหรือการเรียนรู้แบบมีผู้ดูแลตัวเอง** หมายความว่ามันถูกฝึกด้วยข้อมูลหลายรูปแบบที่ไม่มีการติดป้ายกำกับ และไม่ต้องการการติดป้ายกำกับหรือการบันทึกข้อมูลโดยมนุษย์ในกระบวนการฝึก
- **เป็นโมเดลขนาดใหญ่** ที่ใช้เครือข่ายประสาทลึกมากและถูกฝึกด้วยพารามิเตอร์นับพันล้าน
- **มักถูกออกแบบมาเพื่อเป็น ‘พื้นฐาน’ สำหรับโมเดลอื่นๆ** หมายความว่ามันสามารถใช้เป็นจุดเริ่มต้นสำหรับการสร้างโมเดลอื่นๆ โดยการปรับแต่งเพิ่มเติม

![Foundation Models กับ LLMs](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.th.png)

แหล่งที่มาของภาพ: [Essential Guide to Foundation Models and Large Language Models | โดย Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

เพื่ออธิบายความแตกต่างนี้เพิ่มเติม ลองใช้ ChatGPT เป็นตัวอย่าง ในการสร้าง ChatGPT รุ่นแรก โมเดลที่เรียกว่า GPT-3.5 ถูกใช้เป็น Foundation Model ซึ่งหมายความว่า OpenAI ใช้ข้อมูลเฉพาะสำหรับการสนทนาเพื่อสร้างเวอร์ชันที่ปรับแต่งของ GPT-3.5 ที่เชี่ยวชาญในการทำงานได้ดีในสถานการณ์การสนทนา เช่น chatbot

![Foundation Model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.th.png)

แหล่งที่มาของภาพ: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### โมเดลโอเพ่นซอร์สกับโมเดลที่เป็นกรรมสิทธิ์

อีกวิธีหนึ่งในการจัดประเภท LLMs คือการพิจารณาว่าเป็นโอเพ่นซอร์สหรือเป็นกรรมสิทธิ์

โมเดลโอเพ่นซอร์สคือโมเดลที่เปิดให้สาธารณะและสามารถใช้งานได้โดยทุกคน มักถูกเผยแพร่โดยบริษัทที่สร้างมันขึ้นมา หรือโดยชุมชนวิจัย โมเดลเหล่านี้สามารถตรวจสอบ แก้ไข และปรับแต่งสำหรับกรณีการใช้งานต่างๆ ใน LLMs อย่างไรก็ตาม โมเดลเหล่านี้ไม่ได้ถูกปรับให้เหมาะสมสำหรับการใช้งานในระดับการผลิตเสมอไป และอาจไม่สามารถทำงานได้ดีเท่ากับโมเดลที่เป็นกรรมสิทธิ์ นอกจากนี้ การสนับสนุนทางการเงินสำหรับโมเดลโอเพ่นซอร์สอาจมีจำกัด และอาจไม่ได้รับการดูแลในระยะยาวหรือไม่ได้รับการอัปเดตด้วยงานวิจัยล่าสุด ตัวอย่างของโมเดลโอเพ่นซอร์สที่ได้รับความนิยม ได้แก่ [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) และ [LLaMA](https://llama.meta.com)

โมเดลที่เป็นกรรมสิทธิ์คือโมเดลที่เป็นของบริษัทและไม่ได้เปิดให้สาธารณะ โมเดลเหล่านี้มักถูกปรับให้เหมาะสมสำหรับการใช้งานในระดับการผลิต อย่างไรก็ตาม โมเดลเหล่านี้ไม่สามารถตรวจสอบ แก้ไข หรือปรับแต่งสำหรับกรณีการใช้งานต่างๆ ได้ นอกจากนี้ โมเดลเหล่านี้ไม่ได้เปิดให้ใช้งานฟรีเสมอไป และอาจต้องการการสมัครสมาชิกหรือการชำระเงินเพื่อใช้งาน นอกจากนี้ ผู้ใช้ไม่มีการควบคุมข้อมูลที่ใช้ในการฝึกโมเดล ซึ่งหมายความว่าพวกเขาต้องไว้วางใจเจ้าของโมเดลในการรับรองความมุ่งมั่นต่อความเป็นส่วนตัวของข้อมูลและการใช้ AI อย่างมีความรับผิดชอบ ตัวอย่างของโมเดลที่เป็นกรรมสิทธิ์ที่ได้รับความนิยม ได้แก่ [OpenAI models](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) หรือ [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst)

### การฝังข้อมูลกับการสร้างภาพกับการสร้างข้อความและโค้ด

LLMs ยังสามารถจัดประเภทตามผลลัพธ์ที่พวกเขาสร้างได้

การฝังข้อมูลคือชุดของโมเดลที่สามารถแปลงข้อความเป็นรูปแบบตัวเลขที่เรียกว่าการฝังข้อมูล ซึ่งเป็นการแสดงผลตัวเลขของข้อความที่ป้อน การฝังข้อมูลทำให้เครื่องจักรเข้าใจความสัมพันธ์ระหว่างคำหรือประโยคได้ง่ายขึ้น และสามารถใช้เป็นอินพุตโดยโมเดลอื่นๆ เช่น โมเดลการจำแนกประเภท หรือโมเดลการจัดกลุ่มที่มีประสิทธิภาพดีกว่าบนข้อมูลตัวเลข โมเดลการฝังข้อมูลมักถูกใช้สำหรับการเรียนรู้แบบถ่ายโอน ซึ่งโมเดลถูกสร้างขึ้นสำหรับงานตัวแทนที่มีข้อมูลมากมาย และจากนั้นน้ำหนักของโมเดล (การฝังข้อมูล) ถูกนำไปใช้ใหม่สำหรับงานต่อเนื่อง ตัวอย่างของหมวดหมู่นี้คือ [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst)

![การฝังข้อมูล](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.th.png)

โมเดลการสร้างภาพคือโมเดลที่สร้างภาพ โมเดลเหล่านี้มักถูกใช้สำหรับการแก้ไขภาพ การสังเคราะห์ภาพ และการแปลภาพ โมเดลการสร้างภาพมักถูกฝึกด้วยชุดข้อมูลขนาดใหญ่ของภาพ เช่น [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst) และสามารถใช้สร้างภาพใหม่หรือแก้ไขภาพที่มีอยู่ด้วยเทคนิคการเติมภาพ การเพิ่มความละเอียด และการปรับสี ตัวอย่างได้แก่ [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) และ [Stable Diffusion models](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst)

![การสร้างภาพ](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.th.png)

โมเดลการสร้างข้อความและโค้ดคือโมเดลที่สร้างข้อความหรือโค้ด โมเดลเหล่านี้มักถูกใช้สำหรับการสรุปข้อความ การแปล และการตอบคำถาม โมเดลการสร้างข้อความมักถูกฝึกด้วยชุดข้อมูลขนาดใหญ่ของข้อความ เช่น [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst) และสามารถใช้สร้างข้อความใหม่หรือตอบคำถาม โมเดลการสร้างโค้ด เช่น [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst) มักถูกฝึกด้วยชุดข้อมูลขนาดใหญ่ของโค้ด เช่น GitHub และสามารถใช้สร้างโค้ดใหม่หรือแก้ไขข้อผิดพลาดในโค้ดที่มีอยู่

![การสร้างข้อความและโค้ด](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.th.png)

### Encoder-Decoder กับ Decoder-only

เพื่อพูดถึงประเภทต่างๆ ของสถาปัตยกรรมของ LLMs ลองใช้การเปรียบเทียบ

ลองจินตนาการว่าผู้จัดการของคุณมอบหมายงานให้คุณเขียนแบบทดสอบสำหรับนักเรียน คุณมีเพื่อนร่วมงานสองคน คนหนึ่งดูแลการสร้างเนื้อหาและอีกคนดูแลการตรวจสอบ

ผู้สร้างเนื้อหาเปรียบเสมือนโมเดล Decoder-only พวกเขาสามารถดูหัวข้อและสิ่งที่คุณเขียนแล้วสร้างเนื้อหาตามนั้น พวกเขาเก่งในการเขียนเนื้อหาที่น่าสนใจและให้ข้อมูล แต่ไม่เก่งในการทำความเข้าใจหัวข้อและวัตถุประสงค์การเรียนรู้ ตัวอย่างของโมเดล Decoder-only คือโมเดลตระกูล GPT เช่น GPT-3

ผู้ตรวจสอบเปรียบเสมือนโมเดล Encoder-only พวกเขาดูเนื้อหาที่เขียนและคำตอบ สังเกตความสัมพันธ์ระหว่างกันและเข้าใจบริบท แต่ไม่เก่งในการสร้างเนื้อหา ตัวอย่างของโมเดล Encoder-only คือ BERT

ลองจินตนาการว่าเรามีคนที่สามารถสร้างและตรวจสอบแบบทดสอบได้ด้วย นี่คือโมเดล Encoder-Decoder ตัวอย่างได้แก่ BART และ T5

### บริการกับโมเดล

ตอนนี้เรามาพูดถึงความแตกต่างระหว่างบริการและโมเดล บริการคือผลิตภัณฑ์ที่นำเสนอโดยผู้ให้บริการคลาวด์ และมักเป็นการรวมกันของโมเดล ข้อมูล และส่วนประกอบอื่นๆ โมเดลคือส่วนประกอบหลักของบริการ และมักเป็น Foundation Model เช่น LLM

บริการมักถูกปรับให้เหมาะสมสำหรับการใช้งานในระดับการผลิต และมักใช้งานง่ายกว่าด้วยอินเทอร์เฟซแบบกราฟิก อย่างไรก็ตาม บริการไม่ได้เปิดให้ใช้งานฟรีเสมอไป และอาจต้องการการสมัครสมาชิกหรือการชำระเงินเพื่อใช้งาน เพื่อแลกกับการใช้ทรัพยากรและอุปกรณ์ของเจ้าของบริการ ลดค่าใช้จ่ายและปรับขนาดได้ง่าย ตัวอย่างของบริการคือ [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst) ซึ่งมีแผนการชำระเงินตามการใช้งาน หมายความว่าผู้ใช้จะถูกเรียกเก็บเงินตามสัดส่วนของการใช้งาน นอกจากนี้ Azure OpenAI Service ยังมีความปลอดภัยระดับองค์กรและกรอบการทำงาน AI ที่มีความรับผิดชอบบนความสามารถของโมเดล

โมเดลคือเพียงแค่เครือข่ายประสาท พร้อมพารามิเตอร์ น้ำหนัก และอื่นๆ อนุญาตให้บริษัทใช้งานในพื้นที่ได้ อย่างไรก็ตาม จะต้องซื้ออุปกรณ์ สร้างโครงสร้างเพื่อปรับขนาด และซื้อใบอนุญาตหรือใช้โมเดลโอเพ่นซอร์ส โมเดลอย่าง LLaMA มีให้ใช้งาน แต่ต้องการพลังการประมวลผลเพื่อรันโมเดล

## วิธีการทดสอบและปรับปรุงด้วยโมเดลต่างๆ เพื่อทำความเข้าใจประสิทธิภาพใน Azure

เมื่อทีมของเราได้สำรวจภูมิทัศน์ LLMs ปัจจุบันและระบุผู้สมัครที่ดีสำหรับสถานการณ์ของพวกเขา ขั้นตอนต่อไปคือการทดสอบโมเดลเหล่านั้นกับข้อมูลและงานของพวกเขา นี่เป็นกระบวนการที่ต้องทำซ้ำ โดยการทดลองและวัดผล
โมเดลส่วนใหญ่ที่เราได้กล่าวถึงในย่อหน้าก่อนหน้านี้ (โมเดลของ OpenAI, โมเดลโอเพ่นซอร์สอย่าง Llama2 และ Hugging Face transformers) มีให้ใช้งานใน [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) ใน [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst)

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) เป็นแพลตฟอร์มคลาวด์ที่ออกแบบมาสำหรับนักพัฒนาเพื่อสร้างแอปพลิเคชัน AI เชิงสร้างสรรค์และจัดการวงจรการพัฒนาทั้งหมด ตั้งแต่การทดลองไปจนถึงการประเมินผล โดยการรวมบริการ Azure AI ทั้งหมดไว้ในศูนย์กลางเดียวที่มี GUI ใช้งานง่าย Model Catalog ใน Azure AI Studio ช่วยให้ผู้ใช้สามารถ:

- ค้นหา Foundation Model ที่สนใจในแคตตาล็อก ไม่ว่าจะเป็นโมเดลที่เป็นกรรมสิทธิ์หรือโอเพ่นซอร์ส โดยสามารถกรองตามงานที่ต้องการ ใบอนุญาต หรือชื่อ เพื่อเพิ่มความสะดวกในการค้นหา โมเดลจะถูกจัดกลุ่มเป็นคอลเลกชัน เช่น Azure OpenAI collection, Hugging Face collection และอื่นๆ

- ตรวจสอบ model card ซึ่งรวมถึงคำอธิบายรายละเอียดเกี่ยวกับการใช้งานที่ตั้งใจไว้และข้อมูลการฝึกอบรม ตัวอย่างโค้ด และผลการประเมินในคลังการประเมินภายใน

- เปรียบเทียบ benchmarks ระหว่างโมเดลและชุดข้อมูลที่มีอยู่ในอุตสาหกรรมเพื่อประเมินว่าโมเดลใดเหมาะสมกับสถานการณ์ธุรกิจ ผ่านหน้าต่าง [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst)

- ปรับแต่งโมเดลด้วยข้อมูลการฝึกอบรมเฉพาะเพื่อปรับปรุงประสิทธิภาพของโมเดลในงานเฉพาะ โดยใช้ความสามารถในการทดลองและติดตามของ Azure AI Studio

- นำโมเดลที่ผ่านการฝึกอบรมล่วงหน้าหรือเวอร์ชันที่ปรับแต่งแล้วไปใช้งานใน inference แบบเรียลไทม์ - การประมวลผลที่มีการจัดการ - หรือ endpoint API แบบ serverless - [จ่ายตามการใช้งาน](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - เพื่อให้แอปพลิเคชันสามารถใช้งานได้

> [!NOTE]
> ไม่ใช่ทุกโมเดลในแคตตาล็อกที่สามารถปรับแต่งและ/หรือใช้งานแบบจ่ายตามการใช้งานได้ในปัจจุบัน โปรดตรวจสอบ model card เพื่อดูรายละเอียดเกี่ยวกับความสามารถและข้อจำกัดของโมเดล

## การปรับปรุงผลลัพธ์ของ LLM

เราได้สำรวจร่วมกับทีมสตาร์ทอัพของเราเกี่ยวกับ LLM ประเภทต่างๆ และแพลตฟอร์มคลาวด์ (Azure Machine Learning) ที่ช่วยให้เราสามารถเปรียบเทียบโมเดลต่างๆ ประเมินผลบนข้อมูลทดสอบ ปรับปรุงประสิทธิภาพ และนำไปใช้งานบน inference endpoints

แต่เมื่อไหร่ที่ควรพิจารณาปรับแต่งโมเดลแทนที่จะใช้โมเดลที่ผ่านการฝึกอบรมล่วงหน้า? มีวิธีอื่นๆ ในการปรับปรุงประสิทธิภาพของโมเดลในงานเฉพาะหรือไม่?

มีหลายวิธีที่ธุรกิจสามารถใช้เพื่อให้ได้ผลลัพธ์ที่ต้องการจาก LLM คุณสามารถเลือกโมเดลประเภทต่างๆ ที่มีระดับการฝึกอบรมแตกต่างกันเมื่อใช้งาน LLM ในการผลิต โดยมีระดับความซับซ้อน ค่าใช้จ่าย และคุณภาพที่แตกต่างกัน นี่คือวิธีการต่างๆ:

- **การออกแบบคำสั่ง (Prompt engineering) พร้อมบริบท** แนวคิดคือการให้บริบทที่เพียงพอเมื่อคุณส่งคำสั่งเพื่อให้ได้คำตอบที่คุณต้องการ

- **Retrieval Augmented Generation, RAG** ข้อมูลของคุณอาจอยู่ในฐานข้อมูลหรือ endpoint เว็บ ตัวอย่างเช่น เพื่อให้แน่ใจว่าข้อมูลนี้หรือส่วนหนึ่งของข้อมูลนี้ถูกรวมไว้ในเวลาที่ส่งคำสั่ง คุณสามารถดึงข้อมูลที่เกี่ยวข้องและทำให้เป็นส่วนหนึ่งของคำสั่งของผู้ใช้

- **โมเดลที่ปรับแต่งแล้ว** ในกรณีนี้ คุณฝึกอบรมโมเดลเพิ่มเติมด้วยข้อมูลของคุณเอง ซึ่งทำให้โมเดลมีความแม่นยำและตอบสนองต่อความต้องการของคุณมากขึ้น แต่ก็อาจมีค่าใช้จ่ายสูง

### การออกแบบคำสั่ง (Prompt Engineering) พร้อมบริบท

LLM ที่ผ่านการฝึกอบรมล่วงหน้าทำงานได้ดีมากในงานภาษาธรรมชาติทั่วไป แม้กระทั่งการเรียกใช้งานด้วยคำสั่งสั้นๆ เช่น ประโยคที่ต้องการให้เติมเต็มหรือคำถาม – ซึ่งเรียกว่า “zero-shot” learning

อย่างไรก็ตาม ยิ่งผู้ใช้สามารถกำหนดคำถามของตนได้มากขึ้น ด้วยคำขอที่ละเอียดและตัวอย่าง – บริบท – คำตอบก็จะยิ่งแม่นยำและใกล้เคียงกับความคาดหวังของผู้ใช้มากขึ้น ในกรณีนี้ เราจะพูดถึง “one-shot” learning หากคำสั่งมีเพียงตัวอย่างเดียว และ “few-shot learning” หากมีตัวอย่างหลายตัวอย่าง การออกแบบคำสั่งพร้อมบริบทเป็นวิธีที่คุ้มค่าที่สุดในการเริ่มต้น

### Retrieval Augmented Generation (RAG)

LLM มีข้อจำกัดที่สามารถใช้ได้เฉพาะข้อมูลที่ถูกใช้ในระหว่างการฝึกอบรมเพื่อสร้างคำตอบ ซึ่งหมายความว่าพวกมันไม่สามารถรู้เกี่ยวกับข้อเท็จจริงที่เกิดขึ้นหลังจากกระบวนการฝึกอบรม และไม่สามารถเข้าถึงข้อมูลที่ไม่เปิดเผยต่อสาธารณะ (เช่น ข้อมูลบริษัท)
สิ่งนี้สามารถแก้ไขได้ด้วย RAG ซึ่งเป็นเทคนิคที่เพิ่มคำสั่งด้วยข้อมูลภายนอกในรูปแบบของส่วนของเอกสาร โดยพิจารณาจากข้อจำกัดของความยาวคำสั่ง ซึ่งได้รับการสนับสนุนโดยเครื่องมือฐานข้อมูล Vector (เช่น [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) ที่ดึงส่วนที่มีประโยชน์จากแหล่งข้อมูลที่กำหนดไว้ล่วงหน้าและเพิ่มเข้าไปในบริบทของคำสั่ง

เทคนิคนี้มีประโยชน์มากเมื่อธุรกิจไม่มีข้อมูลเพียงพอ ไม่มีเวลาเพียงพอ หรือทรัพยากรในการปรับแต่ง LLM แต่ยังต้องการปรับปรุงประสิทธิภาพในงานเฉพาะและลดความเสี่ยงของการสร้างข้อมูลเท็จ เช่น การบิดเบือนความจริงหรือเนื้อหาที่เป็นอันตราย

### โมเดลที่ปรับแต่งแล้ว

การปรับแต่งเป็นกระบวนการที่ใช้การเรียนรู้แบบถ่ายโอน (transfer learning) เพื่อ ‘ปรับ’ โมเดลให้เหมาะสมกับงานที่ต้องการหรือแก้ปัญหาเฉพาะ แตกต่างจากการเรียนรู้แบบ few-shot และ RAG มันส่งผลให้เกิดโมเดลใหม่ที่มีการปรับปรุงน้ำหนักและอคติ มันต้องการชุดตัวอย่างการฝึกอบรมที่ประกอบด้วยอินพุตเดียว (คำสั่ง) และผลลัพธ์ที่เกี่ยวข้อง (การเติมเต็ม)
นี่จะเป็นวิธีที่เหมาะสมหาก:

- **การใช้โมเดลที่ปรับแต่งแล้ว** ธุรกิจต้องการใช้โมเดลที่ปรับแต่งแล้วที่มีความสามารถน้อยกว่า (เช่น embedding models) แทนที่จะใช้โมเดลที่มีประสิทธิภาพสูง ซึ่งส่งผลให้เป็นโซลูชันที่คุ้มค่าและรวดเร็วกว่า

- **พิจารณาความล่าช้า** ความล่าช้ามีความสำคัญสำหรับกรณีการใช้งานเฉพาะ ดังนั้นจึงไม่สามารถใช้คำสั่งที่ยาวมากหรือจำนวนตัวอย่างที่ควรเรียนรู้จากโมเดลที่ไม่เหมาะสมกับข้อจำกัดความยาวคำสั่ง

- **การอัปเดตข้อมูล** ธุรกิจมีข้อมูลคุณภาพสูงและป้ายกำกับความจริงที่ต้องการ และทรัพยากรที่จำเป็นในการรักษาข้อมูลนี้ให้ทันสมัยอยู่เสมอ

### โมเดลที่ฝึกอบรมแล้ว

การฝึกอบรม LLM ตั้งแต่เริ่มต้นเป็นวิธีที่ยากที่สุดและซับซ้อนที่สุดในการนำไปใช้ ต้องการข้อมูลจำนวนมาก ทรัพยากรที่มีความเชี่ยวชาญ และพลังการประมวลผลที่เหมาะสม ตัวเลือกนี้ควรพิจารณาเฉพาะในกรณีที่ธุรกิจมีกรณีการใช้งานเฉพาะด้านและข้อมูลที่เน้นเฉพาะด้านในปริมาณมาก

## ทดสอบความรู้

วิธีใดที่เหมาะสมในการปรับปรุงผลลัพธ์การเติมเต็มของ LLM?

1. การออกแบบคำสั่งพร้อมบริบท
1. RAG
1. โมเดลที่ปรับแต่งแล้ว

A:3, หากคุณมีเวลาและทรัพยากรและข้อมูลคุณภาพสูง การปรับแต่งจะเป็นตัวเลือกที่ดีกว่าในการรักษาความทันสมัย อย่างไรก็ตาม หากคุณต้องการปรับปรุงและไม่มีเวลา ควรพิจารณา RAG ก่อน

## 🚀 ความท้าทาย

ศึกษาข้อมูลเพิ่มเติมเกี่ยวกับวิธีที่คุณสามารถ [ใช้ RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) สำหรับธุรกิจของคุณ

## ทำได้ดีมาก, เรียนรู้ต่อไป

หลังจากจบบทเรียนนี้แล้ว ลองดู [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) ของเราเพื่อเพิ่มพูนความรู้เกี่ยวกับ Generative AI ของคุณ!

ไปที่บทเรียนที่ 3 ซึ่งเราจะมาดูวิธี [สร้างด้วย Generative AI อย่างมีความรับผิดชอบ](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้อง แต่โปรดทราบว่าการแปลโดยอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาดั้งเดิมควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษามืออาชีพ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความผิดที่เกิดจากการใช้การแปลนี้