<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b7629b8ee4d7d874a27213e903d86a7",
  "translation_date": "2025-10-17T23:10:36+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "fa"
}
-->
# بررسی و مقایسه مدل‌های زبانی بزرگ (LLMs)

[![بررسی و مقایسه مدل‌های زبانی بزرگ](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.fa.png)](https://youtu.be/KIRUeDKscfI?si=8BHX1zvwzQBn-PlK)

> _برای مشاهده ویدئوی این درس، روی تصویر بالا کلیک کنید_

در درس قبلی، دیدیم که چگونه هوش مصنوعی تولیدی در حال تغییر چشم‌انداز فناوری است، مدل‌های زبانی بزرگ (LLMs) چگونه کار می‌کنند و یک کسب‌وکار - مانند استارتاپ ما - چگونه می‌تواند از آن‌ها در موارد استفاده خود بهره‌برداری کند و رشد کند! در این فصل، قصد داریم انواع مختلف مدل‌های زبانی بزرگ را مقایسه کنیم تا مزایا و معایب آن‌ها را بهتر درک کنیم.

گام بعدی در مسیر استارتاپ ما، بررسی چشم‌انداز فعلی مدل‌های زبانی بزرگ و درک اینکه کدام یک برای موارد استفاده ما مناسب هستند، است.

## مقدمه

این درس شامل موارد زیر خواهد بود:

- انواع مختلف مدل‌های زبانی بزرگ در چشم‌انداز فعلی.
- آزمایش، تکرار و مقایسه مدل‌های مختلف برای موارد استفاده شما در Azure.
- نحوه استقرار یک مدل زبانی بزرگ.

## اهداف یادگیری

پس از تکمیل این درس، شما قادر خواهید بود:

- مدل مناسب برای موارد استفاده خود را انتخاب کنید.
- نحوه آزمایش، تکرار و بهبود عملکرد مدل خود را درک کنید.
- بدانید که کسب‌وکارها چگونه مدل‌ها را مستقر می‌کنند.

## درک انواع مختلف مدل‌های زبانی بزرگ

مدل‌های زبانی بزرگ می‌توانند بر اساس معماری، داده‌های آموزشی و موارد استفاده خود دسته‌بندی شوند. درک این تفاوت‌ها به استارتاپ ما کمک می‌کند تا مدل مناسب برای سناریو را انتخاب کند و نحوه آزمایش، تکرار و بهبود عملکرد را بفهمد.

انواع مختلفی از مدل‌های زبانی بزرگ وجود دارد و انتخاب شما بستگی به هدف استفاده، داده‌های شما، بودجه و موارد دیگر دارد.

بسته به اینکه آیا قصد دارید از مدل‌ها برای تولید متن، صدا، ویدئو، تصویر و غیره استفاده کنید، ممکن است نوع متفاوتی از مدل را انتخاب کنید.

- **تشخیص صدا و گفتار**. برای این منظور، مدل‌های نوع Whisper انتخاب بسیار خوبی هستند زیرا عمومی بوده و برای تشخیص گفتار طراحی شده‌اند. این مدل‌ها بر روی داده‌های صوتی متنوع آموزش دیده‌اند و می‌توانند تشخیص گفتار چندزبانه انجام دهند. اطلاعات بیشتر درباره [مدل‌های نوع Whisper را اینجا بخوانید](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **تولید تصویر**. برای تولید تصویر، DALL-E و Midjourney دو انتخاب بسیار شناخته‌شده هستند. DALL-E توسط Azure OpenAI ارائه می‌شود. [اطلاعات بیشتر درباره DALL-E را اینجا بخوانید](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) و همچنین در فصل ۹ این دوره آموزشی.

- **تولید متن**. بیشتر مدل‌ها برای تولید متن آموزش دیده‌اند و شما انتخاب‌های متنوعی از GPT-3.5 تا GPT-4 دارید. این مدل‌ها هزینه‌های متفاوتی دارند و GPT-4 گران‌ترین است. ارزش دارد که به [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) مراجعه کنید تا ارزیابی کنید کدام مدل‌ها از نظر قابلیت و هزینه بهترین گزینه برای نیازهای شما هستند.

- **چند‌حالتی**. اگر به دنبال مدیریت انواع مختلف داده‌ها در ورودی و خروجی هستید، ممکن است بخواهید مدل‌هایی مانند [gpt-4 turbo با قابلیت دیداری یا gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) را بررسی کنید - آخرین نسخه‌های مدل‌های OpenAI - که قادر به ترکیب پردازش زبان طبیعی با درک بصری هستند و امکان تعامل از طریق رابط‌های چند‌حالتی را فراهم می‌کنند.

انتخاب یک مدل به معنای دریافت برخی قابلیت‌های پایه است، اما این ممکن است کافی نباشد. اغلب شما داده‌های خاص شرکت خود را دارید که باید به نوعی به مدل زبانی بزرگ منتقل کنید. چندین روش مختلف برای این کار وجود دارد که در بخش‌های بعدی بیشتر توضیح داده خواهد شد.

### مدل‌های پایه در مقابل مدل‌های زبانی بزرگ

اصطلاح مدل پایه توسط [پژوهشگران دانشگاه استنفورد](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) معرفی شد و به عنوان یک مدل هوش مصنوعی تعریف شد که معیارهای خاصی را دنبال می‌کند، مانند:

- **آن‌ها با استفاده از یادگیری بدون نظارت یا یادگیری خودنظارتی آموزش داده می‌شوند**، به این معنا که بر روی داده‌های چند‌حالتی بدون برچسب آموزش داده می‌شوند و نیازی به برچسب‌گذاری یا حاشیه‌نویسی انسانی برای فرآیند آموزش ندارند.
- **آن‌ها مدل‌های بسیار بزرگی هستند**، بر اساس شبکه‌های عصبی بسیار عمیق که بر روی میلیاردها پارامتر آموزش داده شده‌اند.
- **آن‌ها معمولاً به عنوان یک "پایه" برای مدل‌های دیگر طراحی شده‌اند**، به این معنا که می‌توانند به عنوان نقطه شروع برای ساخت مدل‌های دیگر استفاده شوند، که این کار با تنظیم دقیق انجام می‌شود.

![مدل‌های پایه در مقابل مدل‌های زبانی بزرگ](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.fa.png)

منبع تصویر: [راهنمای ضروری برای مدل‌های پایه و مدل‌های زبانی بزرگ | نوشته بابار م بهاتی | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

برای روشن‌تر کردن این تفاوت، بیایید ChatGPT را به عنوان مثال در نظر بگیریم. برای ساخت نسخه اول ChatGPT، مدلی به نام GPT-3.5 به عنوان مدل پایه استفاده شد. این به این معناست که OpenAI از برخی داده‌های خاص چت برای ایجاد نسخه تنظیم‌شده‌ای از GPT-3.5 استفاده کرد که در سناریوهای مکالمه‌ای، مانند چت‌بات‌ها، عملکرد خوبی داشت.

![مدل پایه](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.fa.png)

منبع تصویر: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### مدل‌های متن‌باز در مقابل مدل‌های اختصاصی

یکی دیگر از روش‌های دسته‌بندی مدل‌های زبانی بزرگ این است که آیا آن‌ها متن‌باز هستند یا اختصاصی.

مدل‌های متن‌باز مدل‌هایی هستند که برای عموم در دسترس قرار دارند و هر کسی می‌تواند از آن‌ها استفاده کند. این مدل‌ها اغلب توسط شرکتی که آن‌ها را ایجاد کرده یا جامعه پژوهشی در دسترس قرار می‌گیرند. این مدل‌ها اجازه بررسی، تغییر و سفارشی‌سازی برای موارد استفاده مختلف در مدل‌های زبانی بزرگ را می‌دهند. با این حال، همیشه برای استفاده در تولید بهینه‌سازی نشده‌اند و ممکن است به اندازه مدل‌های اختصاصی عملکرد خوبی نداشته باشند. علاوه بر این، تأمین مالی برای مدل‌های متن‌باز ممکن است محدود باشد و ممکن است در بلندمدت نگهداری نشوند یا با آخرین پژوهش‌ها به‌روزرسانی نشوند. نمونه‌هایی از مدل‌های متن‌باز محبوب شامل [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst)، [Bloom](https://huggingface.co/bigscience/bloom) و [LLaMA](https://llama.meta.com) هستند.

مدل‌های اختصاصی مدل‌هایی هستند که متعلق به یک شرکت هستند و برای عموم در دسترس نیستند. این مدل‌ها اغلب برای استفاده در تولید بهینه‌سازی شده‌اند. با این حال، اجازه بررسی، تغییر یا سفارشی‌سازی برای موارد استفاده مختلف را نمی‌دهند. علاوه بر این، همیشه به صورت رایگان در دسترس نیستند و ممکن است نیاز به اشتراک یا پرداخت هزینه برای استفاده داشته باشند. همچنین، کاربران کنترل کاملی بر داده‌هایی که برای آموزش مدل استفاده می‌شود ندارند، به این معنا که باید به مالک مدل اعتماد کنند که به حفظ حریم خصوصی داده‌ها و استفاده مسئولانه از هوش مصنوعی متعهد باشد. نمونه‌هایی از مدل‌های اختصاصی محبوب شامل [مدل‌های OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst)، [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) یا [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst) هستند.

### جاسازی در مقابل تولید تصویر در مقابل تولید متن و کد

مدل‌های زبانی بزرگ همچنین می‌توانند بر اساس خروجی‌ای که تولید می‌کنند دسته‌بندی شوند.

جاسازی‌ها مجموعه‌ای از مدل‌ها هستند که می‌توانند متن را به صورت عددی تبدیل کنند، که به آن جاسازی گفته می‌شود و نمایشی عددی از متن ورودی است. جاسازی‌ها درک روابط بین کلمات یا جملات را برای ماشین‌ها آسان‌تر می‌کنند و می‌توانند به عنوان ورودی توسط مدل‌های دیگر مصرف شوند، مانند مدل‌های طبقه‌بندی یا مدل‌های خوشه‌بندی که عملکرد بهتری بر روی داده‌های عددی دارند. مدل‌های جاسازی اغلب برای یادگیری انتقالی استفاده می‌شوند، جایی که یک مدل برای یک وظیفه جانشین که داده‌های زیادی برای آن وجود دارد ساخته می‌شود و سپس وزن‌های مدل (جاسازی‌ها) برای وظایف پایین‌دستی دیگر استفاده می‌شوند. نمونه‌ای از این دسته [جاسازی‌های OpenAI](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst) است.

![جاسازی](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.fa.png)

مدل‌های تولید تصویر مدل‌هایی هستند که تصاویر تولید می‌کنند. این مدل‌ها اغلب برای ویرایش تصویر، سنتز تصویر و ترجمه تصویر استفاده می‌شوند. مدل‌های تولید تصویر اغلب بر روی مجموعه داده‌های بزرگ تصاویر، مانند [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst)، آموزش داده می‌شوند و می‌توانند برای تولید تصاویر جدید یا ویرایش تصاویر موجود با تکنیک‌های inpainting، وضوح بالا و رنگ‌آمیزی استفاده شوند. نمونه‌ها شامل [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) و [مدل‌های Stable Diffusion](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst) هستند.

![تولید تصویر](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.fa.png)

مدل‌های تولید متن و کد مدل‌هایی هستند که متن یا کد تولید می‌کنند. این مدل‌ها اغلب برای خلاصه‌سازی متن، ترجمه و پاسخ به سوالات استفاده می‌شوند. مدل‌های تولید متن اغلب بر روی مجموعه داده‌های بزرگ متن، مانند [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst)، آموزش داده می‌شوند و می‌توانند برای تولید متن جدید یا پاسخ به سوالات استفاده شوند. مدل‌های تولید کد، مانند [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst)، اغلب بر روی مجموعه داده‌های بزرگ کد، مانند GitHub، آموزش داده می‌شوند و می‌توانند برای تولید کد جدید یا رفع اشکال در کد موجود استفاده شوند.

![تولید متن و کد](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.fa.png)

### مدل‌های Encoder-Decoder در مقابل مدل‌های فقط Decoder

برای صحبت درباره انواع مختلف معماری مدل‌های زبانی بزرگ، بیایید از یک قیاس استفاده کنیم.

تصور کنید مدیر شما وظیفه‌ای به شما داده است که یک آزمون برای دانش‌آموزان بنویسید. شما دو همکار دارید؛ یکی مسئول ایجاد محتوا و دیگری مسئول بررسی آن‌ها است.

ایجادکننده محتوا مانند یک مدل فقط Decoder است، او می‌تواند به موضوع نگاه کند و ببیند شما چه چیزی نوشته‌اید و سپس بر اساس آن یک دوره بنویسد. آن‌ها در نوشتن محتوای جذاب و آموزنده بسیار خوب هستند، اما در درک موضوع و اهداف یادگیری چندان خوب نیستند. برخی از نمونه‌های مدل‌های Decoder شامل خانواده مدل‌های GPT، مانند GPT-3 هستند.

بررسی‌کننده مانند یک مدل فقط Encoder است، او به دوره نوشته‌شده و پاسخ‌ها نگاه می‌کند، رابطه بین آن‌ها را متوجه می‌شود و زمینه را درک می‌کند، اما در تولید محتوا خوب نیست. نمونه‌ای از مدل فقط Encoder می‌تواند BERT باشد.

تصور کنید که ما کسی را نیز داشته باشیم که بتواند آزمون را ایجاد و بررسی کند، این یک مدل Encoder-Decoder است. برخی از نمونه‌ها شامل BART و T5 هستند.

### سرویس در مقابل مدل

حالا، بیایید درباره تفاوت بین سرویس و مدل صحبت کنیم. سرویس یک محصول است که توسط یک ارائه‌دهنده خدمات ابری ارائه می‌شود و اغلب ترکیبی از مدل‌ها، داده‌ها و اجزای دیگر است. مدل هسته اصلی یک سرویس است و اغلب یک مدل پایه، مانند یک مدل زبانی بزرگ، است.

سرویس‌ها اغلب برای استفاده در تولید بهینه‌سازی شده‌اند و اغلب از طریق یک رابط کاربری گرافیکی استفاده آسان‌تری نسبت به مدل‌ها دارند. با این حال، سرویس‌ها همیشه رایگان نیستند و ممکن است نیاز به اشتراک یا پرداخت هزینه برای استفاده داشته باشند، در ازای استفاده از تجهیزات و منابع مالک سرویس، بهینه‌سازی هزینه‌ها و مقیاس‌پذیری آسان. نمونه‌ای از یک سرویس [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst) است که یک طرح نرخ پرداخت به‌ازای‌استفاده ارائه می‌دهد، به این معنا که کاربران به نسبت میزان استفاده خود از سرویس هزینه پرداخت می‌کنند. همچنین، Azure OpenAI Service امنیت درجه سازمانی و چارچوب هوش مصنوعی مسئولانه را بر روی قابلیت‌های مدل‌ها ارائه می‌دهد.

مدل‌ها فقط شبکه عصبی هستند، با پارامترها، وزن‌ها و موارد دیگر. این امکان را به شرکت‌ها می‌دهد که به صورت محلی اجرا کنند، اما نیاز به خرید تجهیزات، ساختار برای مقیاس‌پذیری و خرید مجوز یا استفاده از مدل متن‌باز دارند. مدلی مانند LLaMA برای استفاده در دسترس است و نیاز به قدرت محاسباتی برای اجرای مدل دارد.

## نحوه آزمایش و تکرار با مدل‌های مختلف برای درک عملکرد در Azure

پس از اینکه تیم ما چشم‌انداز فعلی مدل‌های زبانی بزرگ را بررسی کرد و برخی از کاندیداهای مناسب برای سناریوهای خود را شناسایی کرد، گام بعدی آزمایش آن‌ها بر روی داده‌ها و بار کاری خود است. این یک فرآیند تکراری است که از طریق آزمایش‌ها و اندازه‌گیری‌ها انجام می‌شود.
بیشتر مدل‌هایی که در پاراگراف‌های قبلی به آن‌ها اشاره کردیم (مدل‌های OpenAI، مدل‌های متن‌باز مانند Llama2 و Hugging Face transformers) در [کاتالوگ مدل](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) در [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst) موجود هستند.

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) یک پلتفرم ابری است که برای توسعه‌دهندگان طراحی شده تا برنامه‌های هوش مصنوعی تولیدی بسازند و کل چرخه توسعه را - از آزمایش تا ارزیابی - مدیریت کنند. این پلتفرم با ترکیب تمام خدمات هوش مصنوعی Azure در یک مرکز واحد و رابط کاربری آسان، این امکان را فراهم می‌کند. کاتالوگ مدل در Azure AI Studio به کاربران اجازه می‌دهد:

- مدل پایه مورد نظر را در کاتالوگ پیدا کنند - چه اختصاصی باشد و چه متن‌باز - با فیلتر کردن بر اساس وظیفه، مجوز یا نام. برای بهبود قابلیت جستجو، مدل‌ها در مجموعه‌هایی مانند مجموعه Azure OpenAI، مجموعه Hugging Face و موارد دیگر سازماندهی شده‌اند.

![کاتالوگ مدل](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.fa.png)

- کارت مدل را بررسی کنند، که شامل توضیحات دقیق در مورد استفاده مورد نظر و داده‌های آموزشی، نمونه‌های کد و نتایج ارزیابی در کتابخانه ارزیابی داخلی است.

![کارت مدل](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.fa.png)

- مقایسه معیارها بین مدل‌ها و مجموعه داده‌های موجود در صنعت برای ارزیابی اینکه کدام یک با سناریوی کسب‌وکار مطابقت دارد، از طریق پنل [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![معیارهای مدل](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.fa.png)

- مدل را با داده‌های آموزشی سفارشی تنظیم کنند تا عملکرد مدل در یک بار کاری خاص بهبود یابد، با استفاده از قابلیت‌های آزمایش و ردیابی Azure AI Studio.

![تنظیم مدل](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.fa.png)

- مدل پیش‌آموزش‌دیده یا نسخه تنظیم‌شده آن را برای استنتاج بلادرنگ از راه دور - محاسبه مدیریت‌شده - یا نقطه پایانی API بدون سرور - [پرداخت به ازای استفاده](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - مستقر کنند تا برنامه‌ها بتوانند از آن استفاده کنند.

![استقرار مدل](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.fa.png)

> [!NOTE]
> همه مدل‌های موجود در کاتالوگ در حال حاضر برای تنظیم و/یا استقرار پرداخت به ازای استفاده در دسترس نیستند. برای جزئیات در مورد قابلیت‌ها و محدودیت‌های مدل، کارت مدل را بررسی کنید.

## بهبود نتایج LLM

ما با تیم استارتاپ خود انواع مختلفی از LLM‌ها و یک پلتفرم ابری (Azure Machine Learning) را بررسی کردیم که به ما امکان مقایسه مدل‌های مختلف، ارزیابی آن‌ها بر روی داده‌های آزمایشی، بهبود عملکرد و استقرار آن‌ها بر روی نقاط پایانی استنتاج را می‌دهد.

اما چه زمانی باید تنظیم یک مدل را به جای استفاده از مدل پیش‌آموزش‌دیده در نظر گرفت؟ آیا روش‌های دیگری برای بهبود عملکرد مدل در بارهای کاری خاص وجود دارد؟

چندین روش وجود دارد که یک کسب‌وکار می‌تواند برای دستیابی به نتایج مورد نیاز از یک LLM استفاده کند. شما می‌توانید انواع مختلفی از مدل‌ها با درجات مختلف آموزش را هنگام استقرار یک LLM در تولید انتخاب کنید، با سطوح مختلف پیچیدگی، هزینه و کیفیت. در اینجا چند روش مختلف آورده شده است:

- **مهندسی درخواست با زمینه**. ایده این است که هنگام درخواست، زمینه کافی ارائه دهید تا پاسخ‌های مورد نیاز را دریافت کنید.

- **تولید بازیابی افزوده (RAG)**. داده‌های شما ممکن است در یک پایگاه داده یا نقطه پایانی وب وجود داشته باشد. برای اطمینان از اینکه این داده‌ها یا زیرمجموعه‌ای از آن‌ها در زمان درخواست گنجانده شده‌اند، می‌توانید داده‌های مرتبط را بازیابی کرده و آن را بخشی از درخواست کاربر کنید.

- **مدل تنظیم‌شده**. در اینجا، شما مدل را بیشتر بر روی داده‌های خود آموزش داده‌اید که منجر به دقیق‌تر و پاسخگوتر شدن مدل به نیازهای شما می‌شود، اما ممکن است هزینه‌بر باشد.

![استقرار LLM‌ها](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.fa.png)

منبع تصویر: [چهار روش استقرار LLM‌ها توسط شرکت‌ها | وبلاگ Fiddler AI](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### مهندسی درخواست با زمینه

LLM‌های پیش‌آموزش‌دیده در وظایف عمومی زبان طبیعی بسیار خوب عمل می‌کنند، حتی با یک درخواست کوتاه، مانند یک جمله برای تکمیل یا یک سؤال - که به آن یادگیری "صفر شات" گفته می‌شود.

با این حال، هرچه کاربر بتواند درخواست خود را با جزئیات و مثال‌ها - یعنی زمینه - بهتر بیان کند، پاسخ دقیق‌تر و نزدیک‌تر به انتظارات کاربر خواهد بود. در این حالت، اگر درخواست فقط شامل یک مثال باشد، از یادگیری "یک شات" صحبت می‌کنیم و اگر شامل چندین مثال باشد، از یادگیری "چند شات" صحبت می‌کنیم. مهندسی درخواست با زمینه، مقرون‌به‌صرفه‌ترین روش برای شروع است.

### تولید بازیابی افزوده (RAG)

LLM‌ها محدودیتی دارند که فقط می‌توانند از داده‌هایی که در طول آموزش آن‌ها استفاده شده است برای تولید پاسخ استفاده کنند. این بدان معناست که آن‌ها هیچ اطلاعاتی درباره وقایعی که پس از فرآیند آموزش رخ داده‌اند ندارند و نمی‌توانند به اطلاعات غیرعمومی (مانند داده‌های شرکت) دسترسی داشته باشند.
این محدودیت را می‌توان از طریق RAG برطرف کرد، تکنیکی که درخواست را با داده‌های خارجی به صورت بخش‌هایی از اسناد تقویت می‌کند، با در نظر گرفتن محدودیت‌های طول درخواست. این تکنیک توسط ابزارهای پایگاه داده برداری (مانند [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) پشتیبانی می‌شود که بخش‌های مفید را از منابع داده از پیش تعریف‌شده بازیابی کرده و آن‌ها را به زمینه درخواست اضافه می‌کنند.

این تکنیک زمانی بسیار مفید است که یک کسب‌وکار داده کافی، زمان کافی یا منابع لازم برای تنظیم یک LLM را ندارد، اما همچنان می‌خواهد عملکرد را در یک بار کاری خاص بهبود بخشد و خطرات جعل، یعنی تحریف واقعیت یا محتوای مضر را کاهش دهد.

### مدل تنظیم‌شده

تنظیم مدل فرآیندی است که از یادگیری انتقالی برای "انطباق" مدل با یک وظیفه پایین‌دستی یا حل یک مشکل خاص استفاده می‌کند. برخلاف یادگیری چند شات و RAG، این فرآیند منجر به ایجاد یک مدل جدید با وزن‌ها و بایاس‌های به‌روزرسانی‌شده می‌شود. این فرآیند نیازمند مجموعه‌ای از مثال‌های آموزشی است که شامل یک ورودی (درخواست) و خروجی مرتبط با آن (تکمیل) می‌شود.
این روش ترجیح داده می‌شود اگر:

- **استفاده از مدل‌های تنظیم‌شده**. یک کسب‌وکار بخواهد از مدل‌های تنظیم‌شده کم‌قدرت‌تر (مانند مدل‌های جاسازی) به جای مدل‌های با عملکرد بالا استفاده کند، که منجر به یک راه‌حل مقرون‌به‌صرفه‌تر و سریع‌تر می‌شود.

- **در نظر گرفتن تأخیر**. تأخیر برای یک مورد استفاده خاص مهم است، بنابراین امکان استفاده از درخواست‌های بسیار طولانی یا تعداد مثال‌هایی که باید از مدل یاد گرفته شود با محدودیت طول درخواست سازگار نیست.

- **به‌روز ماندن**. یک کسب‌وکار داده‌های باکیفیت بالا و برچسب‌های حقیقت زمینی زیادی دارد و منابع لازم برای نگهداری این داده‌ها به‌روز در طول زمان را دارد.

### مدل آموزش‌دیده

آموزش یک LLM از ابتدا بدون شک دشوارترین و پیچیده‌ترین روش برای اتخاذ است، که نیازمند حجم عظیمی از داده‌ها، منابع ماهر و قدرت محاسباتی مناسب است. این گزینه فقط در سناریویی باید در نظر گرفته شود که یک کسب‌وکار یک مورد استفاده خاص دامنه‌ای و مقدار زیادی داده متمرکز بر دامنه داشته باشد.

## بررسی دانش

چه رویکردی می‌تواند برای بهبود نتایج تکمیل LLM مناسب باشد؟

1. مهندسی درخواست با زمینه  
1. RAG  
1. مدل تنظیم‌شده  

پاسخ: 3، اگر زمان و منابع و داده‌های باکیفیت دارید، تنظیم مدل گزینه بهتری برای به‌روز ماندن است. با این حال، اگر به دنبال بهبود هستید و زمان کافی ندارید، ابتدا RAG را در نظر بگیرید.

## 🚀 چالش

بیشتر درباره اینکه چگونه می‌توانید [از RAG استفاده کنید](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) برای کسب‌وکار خود مطالعه کنید.

## کار عالی، ادامه یادگیری شما

پس از تکمیل این درس، مجموعه [یادگیری هوش مصنوعی تولیدی](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) ما را بررسی کنید تا دانش خود را در زمینه هوش مصنوعی تولیدی ارتقا دهید!

به درس 3 بروید، جایی که به بررسی نحوه [ساخت با هوش مصنوعی تولیدی به‌صورت مسئولانه](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst) خواهیم پرداخت!

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حیاتی، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.