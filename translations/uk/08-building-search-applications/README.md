<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "58953c08b8ba7073b836d4270ea0fe86",
  "translation_date": "2025-10-18T02:11:35+00:00",
  "source_file": "08-building-search-applications/README.md",
  "language_code": "uk"
}
-->
# Створення пошукових додатків

[![Вступ до генеративного штучного інтелекту та великих мовних моделей](../../../translated_images/08-lesson-banner.8fff48c566dad08a1cbb9f4b4a2c16adfdd288a7bbfffdd30770b466fe08c25c.uk.png)](https://youtu.be/W0-nzXjOjr0?si=GcsqiTTvd7RKbo7V)

> > _Натисніть на зображення вище, щоб переглянути відео цього уроку_

Великі мовні моделі (LLM) - це не лише чат-боти та генерація тексту. За допомогою векторних представлень даних, відомих як ембеддинги, можна створювати пошукові додатки. Ембеддинги дозволяють здійснювати семантичний пошук даних.

У цьому уроці ви створите пошуковий додаток для нашого освітнього стартапу. Наш стартап - це неприбуткова організація, яка надає безкоштовну освіту студентам у країнах, що розвиваються. У нас є велика кількість відео на YouTube, які студенти можуть використовувати для навчання про штучний інтелект. Ми хочемо створити пошуковий додаток, який дозволить студентам знаходити відео на YouTube, вводячи запитання.

Наприклад, студент може запитати: "Що таке Jupyter Notebooks?" або "Що таке Azure ML?", і пошуковий додаток поверне список відео на YouTube, які відповідають запитанню. Більше того, додаток надасть посилання на той момент у відео, де знаходиться відповідь на запитання.

## Вступ

У цьому уроці ми розглянемо:

- Семантичний пошук vs пошук за ключовими словами.
- Що таке текстові ембеддинги.
- Створення індексу текстових ембеддингів.
- Пошук в індексі текстових ембеддингів.

## Цілі навчання

Після завершення цього уроку ви зможете:

- Розрізняти семантичний пошук і пошук за ключовими словами.
- Пояснити, що таке текстові ембеддинги.
- Створити додаток, який використовує ембеддинги для пошуку даних.

## Чому варто створювати пошуковий додаток?

Створення пошукового додатка допоможе вам зрозуміти, як використовувати ембеддинги для пошуку даних. Ви також навчитеся створювати пошуковий додаток, який студенти зможуть використовувати для швидкого пошуку інформації.

Урок включає індекс ембеддингів транскриптів відео з YouTube-каналу Microsoft [AI Show](https://www.youtube.com/playlist?list=PLlrxD0HtieHi0mwteKBOfEeOYf0LJU4O1). AI Show - це YouTube-канал, який навчає штучному інтелекту та машинному навчанню. Індекс ембеддингів містить ембеддинги для кожного транскрипту відео на YouTube до жовтня 2023 року. Ви використаєте цей індекс для створення пошукового додатка для нашого стартапу. Пошуковий додаток повертає посилання на той момент у відео, де знаходиться відповідь на запитання. Це чудовий спосіб для студентів швидко знаходити потрібну інформацію.

Ось приклад семантичного запиту для запитання "Чи можна використовувати rstudio з azure ml?". Зверніть увагу на URL-адресу YouTube, вона містить часову мітку, яка веде до моменту у відео, де знаходиться відповідь на запитання.

![Семантичний запит для запитання "Чи можна використовувати rstudio з Azure ML"](../../../translated_images/query-results.bb0480ebf025fac69c5179ad4d53b6627d643046838c857dc9e2b1281f1cdeb7.uk.png)

## Що таке семантичний пошук?

Можливо, ви запитаєте, що таке семантичний пошук? Семантичний пошук - це техніка пошуку, яка використовує семантику або значення слів у запиті для повернення релевантних результатів.

Ось приклад семантичного пошуку. Припустимо, ви хочете купити автомобіль, і вводите запит "мій автомобіль мрії". Семантичний пошук розуміє, що ви не `мрієте` про автомобіль, а шукаєте свій `ідеальний` автомобіль. Семантичний пошук розуміє ваш намір і повертає релевантні результати. Альтернативою є `пошук за ключовими словами`, який буквально шукає мрії про автомобілі і часто повертає нерелевантні результати.

## Що таке текстові ембеддинги?

[Текстові ембеддинги](https://en.wikipedia.org/wiki/Word_embedding?WT.mc_id=academic-105485-koreyst) - це техніка представлення тексту, яка використовується в [обробці природної мови](https://en.wikipedia.org/wiki/Natural_language_processing?WT.mc_id=academic-105485-koreyst). Текстові ембеддинги - це семантичні числові представлення тексту. Ембеддинги використовуються для представлення даних у формі, яка легко зрозуміла машині. Існує багато моделей для створення текстових ембеддингів, у цьому уроці ми зосередимося на генерації ембеддингів за допомогою моделі OpenAI Embedding.

Ось приклад: уявіть, що наступний текст є частиною транскрипту одного з епізодів на YouTube-каналі AI Show:

```text
Today we are going to learn about Azure Machine Learning.
```

Ми передаємо текст до OpenAI Embedding API, і він повертає наступний ембеддинг, що складається з 1536 чисел, також відомих як вектор. Кожне число у векторі представляє різний аспект тексту. Для стислості наведено перші 10 чисел у векторі.

```python
[-0.006655829958617687, 0.0026128944009542465, 0.008792596869170666, -0.02446001023054123, -0.008540431968867779, 0.022071078419685364, -0.010703742504119873, 0.003311325330287218, -0.011632772162556648, -0.02187200076878071, ...]
```

## Як створюється індекс ембеддингів?

Індекс ембеддингів для цього уроку був створений за допомогою серії скриптів на Python. Ви знайдете ці скрипти разом з інструкціями у [README](./scripts/README.md?WT.mc_id=academic-105485-koreyst) у папці 'scripts' цього уроку. Вам не потрібно запускати ці скрипти, щоб завершити урок, оскільки індекс ембеддингів вже надано.

Скрипти виконують наступні операції:

1. Завантажується транскрипт для кожного відео на YouTube з плейлиста [AI Show](https://www.youtube.com/playlist?list=PLlrxD0HtieHi0mwteKBOfEeOYf0LJU4O1).
2. Використовуючи [OpenAI Functions](https://learn.microsoft.com/azure/ai-services/openai/how-to/function-calling?WT.mc_id=academic-105485-koreyst), здійснюється спроба витягти ім'я спікера з перших 3 хвилин транскрипту відео. Ім'я спікера для кожного відео зберігається в індексі ембеддингів під назвою `embedding_index_3m.json`.
3. Текст транскрипту розбивається на **3-хвилинні текстові сегменти**. Сегмент включає приблизно 20 слів, які перекриваються з наступним сегментом, щоб забезпечити, що ембеддинг для сегменту не буде обірваний, і щоб надати кращий контекст для пошуку.
4. Кожен текстовий сегмент передається до OpenAI Chat API для створення резюме тексту довжиною 60 слів. Резюме також зберігається в індексі ембеддингів `embedding_index_3m.json`.
5. Нарешті, текст сегменту передається до OpenAI Embedding API. Embedding API повертає вектор з 1536 чисел, які представляють семантичне значення сегменту. Сегмент разом із вектором OpenAI Embedding зберігається в індексі ембеддингів `embedding_index_3m.json`.

### Векторні бази даних

Для спрощення уроку індекс ембеддингів зберігається у файлі JSON під назвою `embedding_index_3m.json` і завантажується у Pandas DataFrame. Однак у виробничих умовах індекс ембеддингів буде зберігатися у векторній базі даних, такій як [Azure Cognitive Search](https://learn.microsoft.com/training/modules/improve-search-results-vector-search?WT.mc_id=academic-105485-koreyst), [Redis](https://cookbook.openai.com/examples/vector_databases/redis/readme?WT.mc_id=academic-105485-koreyst), [Pinecone](https://cookbook.openai.com/examples/vector_databases/pinecone/readme?WT.mc_id=academic-105485-koreyst), [Weaviate](https://cookbook.openai.com/examples/vector_databases/weaviate/readme?WT.mc_id=academic-105485-koreyst) тощо.

## Розуміння косинусної схожості

Ми дізналися про текстові ембеддинги, наступним кроком є навчання використання текстових ембеддингів для пошуку даних, зокрема для знаходження найбільш схожих ембеддингів до заданого запиту за допомогою косинусної схожості.

### Що таке косинусна схожість?

Косинусна схожість - це міра схожості між двома векторами, яку також називають `пошуком найближчих сусідів`. Щоб виконати пошук за косинусною схожістю, потрібно _векторизувати_ текст _запиту_ за допомогою OpenAI Embedding API. Потім обчислити _косинусну схожість_ між вектором запиту та кожним вектором в індексі ембеддингів. Пам'ятайте, що індекс ембеддингів має вектор для кожного текстового сегменту транскрипту відео на YouTube. Нарешті, результати сортуються за косинусною схожістю, і текстові сегменти з найвищою косинусною схожістю є найбільш схожими до запиту.

З математичної точки зору, косинусна схожість вимірює косинус кута між двома векторами, проєктованими в багатовимірному просторі. Це вимірювання є корисним, оскільки, якщо два документи знаходяться далеко один від одного за евклідовою відстанню через розмір, вони все одно можуть мати менший кут між ними і, відповідно, більшу косинусну схожість. Для отримання додаткової інформації про рівняння косинусної схожості дивіться [Cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity?WT.mc_id=academic-105485-koreyst).

## Створення вашого першого пошукового додатка

Далі ми навчимося створювати пошуковий додаток за допомогою ембеддингів. Пошуковий додаток дозволить студентам шукати відео, вводячи запитання. Додаток поверне список відео, які відповідають запитанню, а також посилання на той момент у відео, де знаходиться відповідь на запитання.

Це рішення було створено та протестовано на Windows 11, macOS та Ubuntu 22.04 з використанням Python 3.10 або новішої версії. Ви можете завантажити Python з [python.org](https://www.python.org/downloads/?WT.mc_id=academic-105485-koreyst).

## Завдання - створення пошукового додатка для допомоги студентам

На початку цього уроку ми представили наш стартап. Тепер настав час допомогти студентам створити пошуковий додаток для їхніх завдань.

У цьому завданні ви створите сервіси Azure OpenAI, які будуть використовуватися для створення пошукового додатка. Ви створите наступні сервіси Azure OpenAI. Для виконання цього завдання вам знадобиться підписка на Azure.

### Запуск Azure Cloud Shell

1. Увійдіть до [порталу Azure](https://portal.azure.com/?WT.mc_id=academic-105485-koreyst).
2. Виберіть значок Cloud Shell у верхньому правому куті порталу Azure.
3. Виберіть **Bash** як тип середовища.

#### Створення групи ресурсів

> Для цих інструкцій ми використовуємо групу ресурсів під назвою "semantic-video-search" у регіоні East US.
> Ви можете змінити назву групи ресурсів, але при зміні місця розташування ресурсів перевірте [таблицю доступності моделей](https://aka.ms/oai/models?WT.mc_id=academic-105485-koreyst).

```shell
az group create --name semantic-video-search --location eastus
```

#### Створення ресурсу Azure OpenAI Service

У Azure Cloud Shell виконайте наступну команду для створення ресурсу Azure OpenAI Service.

```shell
az cognitiveservices account create --name semantic-video-openai --resource-group semantic-video-search \
    --location eastus --kind OpenAI --sku s0
```

#### Отримання кінцевої точки та ключів для використання в цьому додатку

У Azure Cloud Shell виконайте наступні команди, щоб отримати кінцеву точку та ключі для ресурсу Azure OpenAI Service.

```shell
az cognitiveservices account show --name semantic-video-openai \
   --resource-group  semantic-video-search | jq -r .properties.endpoint
az cognitiveservices account keys list --name semantic-video-openai \
   --resource-group semantic-video-search | jq -r .key1
```

#### Розгортання моделі OpenAI Embedding

У Azure Cloud Shell виконайте наступну команду для розгортання моделі OpenAI Embedding.

```shell
az cognitiveservices account deployment create \
    --name semantic-video-openai \
    --resource-group  semantic-video-search \
    --deployment-name text-embedding-ada-002 \
    --model-name text-embedding-ada-002 \
    --model-version "2"  \
    --model-format OpenAI \
    --sku-capacity 100 --sku-name "Standard"
```

## Рішення

Відкрийте [ноутбук з рішенням](./python/aoai-solution.ipynb?WT.mc_id=academic-105485-koreyst) у GitHub Codespaces і дотримуйтесь інструкцій у Jupyter Notebook.

Коли ви запустите ноутбук, вам буде запропоновано ввести запит. Вікно введення виглядатиме так:

![Вікно введення для введення запиту користувачем](../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.uk.png)

## Чудова робота! Продовжуйте навчання

Після завершення цього уроку перегляньте нашу [колекцію навчальних матеріалів про генеративний штучний інтелект](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), щоб продовжити вдосконалювати свої знання про генеративний штучний інтелект!

Перейдіть до уроку 9, де ми розглянемо, як [створювати додатки для генерації зображень](../09-building-image-applications/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Відмова від відповідальності**:  
Цей документ був перекладений за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критичної інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникають внаслідок використання цього перекладу.