<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "807f0d9fc1747e796433534e1be6a98a",
  "translation_date": "2025-10-18T02:17:25+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "uk"
}
-->
[![Моделі з відкритим кодом](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.uk.png)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Тонке налаштування вашої LLM

Використання великих мовних моделей для створення додатків генеративного штучного інтелекту супроводжується новими викликами. Основною проблемою є забезпечення якості відповідей (точності та релевантності) у контенті, який генерує модель для конкретного запиту користувача. У попередніх уроках ми обговорювали такі техніки, як інженерія підказок та генерація з розширеним пошуком, які намагаються вирішити проблему шляхом _модифікації вхідних даних підказки_ для існуючої моделі.

У сьогоднішньому уроці ми обговоримо третю техніку — **тонке налаштування**, яка намагається вирішити проблему шляхом _перенавчання самої моделі_ з використанням додаткових даних. Давайте розглянемо деталі.

## Навчальні цілі

Цей урок знайомить з концепцією тонкого налаштування для попередньо навчених мовних моделей, досліджує переваги та виклики цього підходу, а також надає рекомендації щодо того, коли і як використовувати тонке налаштування для покращення продуктивності ваших генеративних моделей штучного інтелекту.

До кінця цього уроку ви зможете відповісти на наступні запитання:

- Що таке тонке налаштування мовних моделей?
- Коли і чому тонке налаштування є корисним?
- Як можна виконати тонке налаштування попередньо навченої моделі?
- Які обмеження тонкого налаштування?

Готові? Почнемо.

## Ілюстрований посібник

Хочете отримати загальне уявлення про те, що ми будемо розглядати, перед тим як заглибитися? Ознайомтеся з цим ілюстрованим посібником, який описує навчальний шлях цього уроку — від вивчення основних концепцій і мотивації для тонкого налаштування до розуміння процесу та найкращих практик для виконання завдання тонкого налаштування. Це захоплююча тема для дослідження, тому не забудьте переглянути сторінку [Ресурси](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) для додаткових посилань, які підтримають вашу самостійну навчальну подорож!

![Ілюстрований посібник з тонкого налаштування мовних моделей](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.uk.png)

## Що таке тонке налаштування мовних моделей?

За визначенням, великі мовні моделі є _попередньо навчені_ на великих обсягах тексту, отриманого з різних джерел, включаючи інтернет. Як ми вже дізналися в попередніх уроках, нам потрібні такі техніки, як _інженерія підказок_ та _генерація з розширеним пошуком_, щоб покращити якість відповідей моделі на запитання користувача ("підказки").

Популярна техніка інженерії підказок передбачає надання моделі більш чітких вказівок щодо того, що очікується у відповіді, або шляхом надання _інструкцій_ (явні вказівки), або _наданням кількох прикладів_ (неявні вказівки). Це називається _навчанням з кількома прикладами_, але воно має два обмеження:

- Ліміти токенів моделі можуть обмежувати кількість прикладів, які ви можете надати, і знижувати ефективність.
- Вартість токенів моделі може зробити додавання прикладів до кожної підказки дорогим і обмежити гнучкість.

Тонке налаштування — це поширена практика в системах машинного навчання, коли ми беремо попередньо навчену модель і перенавчаємо її з новими даними, щоб покращити її продуктивність для конкретного завдання. У контексті мовних моделей ми можемо тонко налаштувати попередньо навчену модель _з використанням спеціально підібраного набору прикладів для конкретного завдання або домену застосування_, щоб створити **кастомну модель**, яка може бути більш точною та релевантною для цього конкретного завдання або домену. Додатковою перевагою тонкого налаштування є те, що воно може також зменшити кількість прикладів, необхідних для навчання з кількома прикладами, — зменшуючи використання токенів і пов'язані з цим витрати.

## Коли і чому ми повинні тонко налаштовувати моделі?

У _цьому_ контексті, коли ми говоримо про тонке налаштування, ми маємо на увазі **супервізоване** тонке налаштування, де перенавчання здійснюється шляхом **додавання нових даних**, які не були частиною оригінального набору даних для навчання. Це відрізняється від підходу несупервізованого тонкого налаштування, де модель перенавчається на оригінальних даних, але з іншими гіперпараметрами.

Головне, що потрібно пам'ятати, це те, що тонке налаштування — це складна техніка, яка вимагає певного рівня експертизи для досягнення бажаних результатів. Якщо виконати його неправильно, воно може не забезпечити очікуваних покращень і навіть погіршити продуктивність моделі для вашого цільового домену.

Отже, перед тим як дізнатися "як" тонко налаштовувати мовні моделі, вам потрібно зрозуміти "чому" ви повинні обрати цей шлях і "коли" почати процес тонкого налаштування. Почніть з того, щоб задати собі ці запитання:

- **Випадок використання**: Який ваш _випадок використання_ для тонкого налаштування? Який аспект поточної попередньо навченої моделі ви хочете покращити?
- **Альтернативи**: Чи пробували ви _інші техніки_ для досягнення бажаних результатів? Використовуйте їх для створення базового рівня для порівняння.
  - Інженерія підказок: Спробуйте техніки, такі як навчання з кількома прикладами, з прикладами релевантних відповідей на підказки. Оцініть якість відповідей.
  - Генерація з розширеним пошуком: Спробуйте доповнити підказки результатами запитів, отриманими шляхом пошуку у ваших даних. Оцініть якість відповідей.
- **Витрати**: Чи визначили ви витрати на тонке налаштування?
  - Налаштовуваність — чи доступна попередньо навчена модель для тонкого налаштування?
  - Зусилля — для підготовки навчальних даних, оцінки та вдосконалення моделі.
  - Обчислення — для запуску завдань тонкого налаштування та розгортання тонко налаштованої моделі.
  - Дані — доступ до достатньої кількості якісних прикладів для впливу тонкого налаштування.
- **Переваги**: Чи підтвердили ви переваги тонкого налаштування?
  - Якість — чи перевершила тонко налаштована модель базовий рівень?
  - Вартість — чи зменшує вона використання токенів, спрощуючи підказки?
  - Розширюваність — чи можна адаптувати базову модель для нових доменів?

Відповівши на ці запитання, ви зможете вирішити, чи є тонке налаштування правильним підходом для вашого випадку використання. Ідеально, якщо підхід є виправданим лише тоді, коли переваги перевищують витрати. Як тільки ви вирішите продовжити, настав час подумати про те, _як_ ви можете тонко налаштувати попередньо навчену модель.

Хочете отримати більше інформації про процес прийняття рішення? Дивіться [Тонке налаштування чи ні](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Як ми можемо тонко налаштувати попередньо навчену модель?

Для тонкого налаштування попередньо навченої моделі вам потрібно мати:

- попередньо навчену модель для тонкого налаштування
- набір даних для використання в тонкому налаштуванні
- середовище для навчання, щоб запустити завдання тонкого налаштування
- середовище для розгортання тонко налаштованої моделі

## Тонке налаштування в дії

Наступні ресурси надають покрокові інструкції, які допоможуть вам пройти реальний приклад використання вибраної моделі з підібраним набором даних. Для роботи з цими навчальними матеріалами вам потрібен обліковий запис у конкретного провайдера, а також доступ до відповідної моделі та наборів даних.

| Провайдер    | Навчальний посібник                                                                                                                                                            | Опис                                                                                                                                                                                                                                                                                                                                                                                                                              |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Як тонко налаштувати чат-моделі](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)             | Дізнайтеся, як тонко налаштувати `gpt-35-turbo` для конкретного домену ("асистент рецептів"), підготувавши навчальні дані, запустивши завдання тонкого налаштування та використовуючи тонко налаштовану модель для інференції.                                                                                                                                                                                                     |
| Azure OpenAI | [Навчальний посібник з тонкого налаштування GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Дізнайтеся, як тонко налаштувати модель `gpt-35-turbo-0613` **на Azure**, виконуючи кроки зі створення та завантаження навчальних даних, запуску завдання тонкого налаштування. Розгорніть і використовуйте нову модель.                                                                                                                                                                                                           |
| Hugging Face | [Тонке налаштування LLM з Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                            | Цей блог-пост проводить вас через процес тонкого налаштування _відкритої LLM_ (наприклад, `CodeLlama 7B`) за допомогою бібліотеки [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) та [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) з використанням відкритих [наборів даних](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) на Hugging Face. |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| 🤗 AutoTrain | [Тонке налаштування LLM з AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                      | AutoTrain (або AutoTrain Advanced) — це бібліотека Python, розроблена Hugging Face, яка дозволяє виконувати тонке налаштування для багатьох різних завдань, включаючи тонке налаштування LLM. AutoTrain — це рішення без коду, і тонке налаштування можна виконати у вашій власній хмарі, на Hugging Face Spaces або локально. Воно підтримує як веб-інтерфейс, так і CLI, а також навчання через конфігураційні файли yaml.                     |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Завдання

Виберіть один із наведених вище навчальних посібників і пройдіть його. _Ми можемо відтворити версію цих навчальних посібників у Jupyter Notebooks у цьому репозиторії лише для довідки. Будь ласка, використовуйте оригінальні джерела безпосередньо, щоб отримати найновіші версії_.

## Чудова робота! Продовжуйте навчання.

Після завершення цього уроку перегляньте нашу [колекцію навчальних матеріалів з генеративного штучного інтелекту](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), щоб продовжити вдосконалювати свої знання про генеративний штучний інтелект!

Вітаємо!! Ви завершили фінальний урок з серії v2 цього курсу! Не зупиняйтеся на досягнутому, продовжуйте навчатися та створювати. \*\*Перегляньте сторінку [РЕСУРСИ](RESOURCES.md?WT.mc_id=academic-105485-koreyst) для списку додаткових пропозицій саме з цієї теми.

Наша серія уроків v1 також була оновлена з додатковими завданнями та концепціями. Тож знайдіть хвилинку, щоб освіжити свої знання — і, будь ласка, [поділіться своїми запитаннями та відгуками](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), щоб допомогти нам покращити ці уроки для спільноти.

---

**Відмова від відповідальності**:  
Цей документ був перекладений за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критичної інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникають внаслідок використання цього перекладу.