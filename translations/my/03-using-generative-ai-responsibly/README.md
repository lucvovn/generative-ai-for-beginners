<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4d57fad773cbeb69c5dd62e65c34200d",
  "translation_date": "2025-10-18T01:55:08+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "my"
}
-->
# Generative AI ကို တာဝန်ရှိရှိ အသုံးပြုခြင်း

[![Generative AI ကို တာဝန်ရှိရှိ အသုံးပြုခြင်း](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.my.png)](https://youtu.be/YOp-e1GjZdA?si=7Wv4wu3x44L1DCVj)

> _အထက်ပါပုံကိုနှိပ်ပြီး ဒီသင်ခန်းစာရဲ့ ဗီဒီယိုကို ကြည့်ပါ_

AI, အထူးသဖြင့် Generative AI ကို စိတ်ဝင်စားဖို့ လွယ်ကူပါတယ်၊ ဒါပေမယ့် သင့်ရဲ့ အသုံးပြုမှုကို တာဝန်ရှိရှိ ပြုလုပ်ဖို့ စဉ်းစားဖို့ လိုအပ်ပါတယ်။ ထုတ်လွှင့်မှုကို တရားမျှတမှု၊ အန္တရာယ်မရှိမှု စသည်တို့ကို အာမခံနိုင်ဖို့ စဉ်းစားဖို့ လိုအပ်ပါတယ်။ ဒီအခန်းမှာ သင့်ကို အဆိုပါအခြေအနေ၊ စဉ်းစားရန်အချက်များနှင့် AI ကို ပိုမိုကောင်းမွန်စွာ အသုံးပြုနိုင်ဖို့ လုပ်ဆောင်နိုင်သော အဆင့်များကို ပေးစွမ်းရန် ရည်ရွယ်ထားပါတယ်။

## နိဒါန်း

ဒီသင်ခန်းစာမှာ အောက်ပါအကြောင်းအရာများကို လေ့လာပါမည်-

- Generative AI အက်ပလီကေးရှင်းများကို တည်ဆောက်ရာတွင် Responsible AI ကို ဦးစားပေးသင့်သော အကြောင်းအရင်း။
- Responsible AI ရဲ့ အခြေခံအချက်များနှင့် Generative AI နှင့် ဆက်စပ်မှု။
- Responsible AI အခြေခံအချက်များကို မဟာဗျူဟာနှင့် ကိရိယာများမှတဆင့် လက်တွေ့ကျကျ အသုံးချနည်း။

## သင်ယူရမည့် ရည်မှန်းချက်များ

ဒီသင်ခန်းစာကို ပြီးမြောက်ပြီးနောက် သင်သည် အောက်ပါအချက်များကို သိရှိမည်-

- Generative AI အက်ပလီကေးရှင်းများကို တည်ဆောက်ရာတွင် Responsible AI ရဲ့ အရေးပါမှု။
- Generative AI အက်ပလီကေးရှင်းများကို တည်ဆောက်ရာတွင် Responsible AI ရဲ့ အခြေခံအချက်များကို စဉ်းစားပြီး အသုံးချရန် အချိန်။
- Responsible AI ကို လက်တွေ့ကျကျ အသုံးချရန် ရရှိနိုင်သော ကိရိယာများနှင့် မဟာဗျူဟာများ။

## Responsible AI ရဲ့ အခြေခံအချက်များ

Generative AI ရဲ့ စိတ်လှုပ်ရှားမှုဟာ အမြင့်ဆုံးအဆင့်ကို ရောက်ရှိနေပါပြီ။ ဒီစိတ်လှုပ်ရှားမှုဟာ Developer အသစ်များ၊ အာရုံစိုက်မှုများနှင့် ရန်ပုံငွေများကို ဒီနယ်ပယ်ထဲသို့ ဆွဲဆောင်လာပါတယ်။ Generative AI ကို အသုံးပြုပြီး ထုတ်ကုန်များနှင့် ကုမ္ပဏီများကို တည်ဆောက်လိုသူများအတွက် ဒီဟာက အလွန်ကောင်းမွန်တဲ့ အခွင့်အရေးဖြစ်ပါတယ်။ ဒါပေမယ့် တာဝန်ရှိရှိ ဆက်လက်လုပ်ဆောင်ဖို့ လိုအပ်ပါတယ်။

ဒီသင်တန်းတစ်ခုလုံးမှာ ကျွန်တော်တို့ startup နှင့် AI ပညာရေးထုတ်ကုန်ကို တည်ဆောက်နေပါတယ်။ ကျွန်တော်တို့ Responsible AI ရဲ့ အခြေခံအချက်များဖြစ်တဲ့ တရားမျှတမှု၊ ပါဝင်မှု၊ ယုံကြည်စိတ်ချရမှု/လုံခြုံမှု၊ လုံခြုံရေးနှင့် ကိုယ်ရေးအချက်အလက်များ၊ ထင်ရှားမှုနှင့် တာဝန်ယူမှုတို့ကို အသုံးပြုမည်ဖြစ်သည်။ ဒီအခြေခံအချက်များနှင့်အတူ Generative AI ကို ကျွန်တော်တို့ရဲ့ ထုတ်ကုန်များတွင် အသုံးပြုမှုနှင့် ဆက်စပ်မှုကို လေ့လာမည်ဖြစ်သည်။

## Responsible AI ကို ဦးစားပေးသင့်သော အကြောင်းအရင်း

ထုတ်ကုန်တစ်ခုကို တည်ဆောက်ရာတွင် လူအခြေပြုနည်းလမ်းကို အသုံးပြုပြီး သင့်ရဲ့ အသုံးပြုသူရဲ့ အကျိုးစီးပွားကို ဦးစားပေးခြင်းက အကောင်းဆုံးရလဒ်များကို ရရှိစေပါသည်။

Generative AI ရဲ့ ထူးခြားမှုက အသုံးပြုသူများအတွက် အကျိုးရှိသော အဖြေများ၊ အချက်အလက်များ၊ လမ်းညွှန်မှုများနှင့် အကြောင်းအရာများကို ဖန်တီးနိုင်စွမ်းဖြစ်ပါတယ်။ ဒီဟာကို လက်စွဲလုပ်ငန်းများ မရှိဘဲ အလွန်အံ့ဩဖွယ် ရလဒ်များကို ရရှိစေပါသည်။ သင့်တော်သော စီမံကိန်းများနှင့် မဟာဗျူဟာများ မရှိပါက၊ ဒါဟာ သင့်ရဲ့ အသုံးပြုသူများ၊ သင့်ထုတ်ကုန်နှင့် လူမှုအဖွဲ့အစည်းအတွက် အန္တရာယ်များကို ဖြစ်စေနိုင်ပါတယ်။

အောက်မှာ ဒီအန္တရာယ်များအချို့ကို ကြည့်လိုက်ရအောင်-

### Hallucinations

Hallucinations ဆိုတာ LLM က အကြောင်းအရာတစ်ခုခုကို အဓိပ္ပါယ်မရှိသောအရာများ သို့မဟုတ် အခြားအချက်အလက်များအရ မှားယွင်းနေသော အရာများကို ထုတ်လွှင့်သောအခါ ဖြစ်ပေါ်လာသော အခြေအနေကို ဖော်ပြသော စကားလုံးဖြစ်သည်။

ဥပမာအားဖြင့် ကျွန်တော်တို့ startup အတွက် ကျောင်းသားများကို သမိုင်းဆိုင်ရာမေးခွန်းများကို မော်ဒယ်ထံ မေးခွန်းမေးနိုင်စေသော အင်္ဂါရပ်တစ်ခုကို တည်ဆောက်လိုက်တယ်ဆိုပါစို့။ ကျောင်းသားတစ်ဦးက `Titanic ရဲ့ အသက်ရှင်ကျန်ရစ်သူ တစ်ဦးတည်းက ဘယ်သူလဲ?` ဆိုပြီး မေးခွန်းမေးလိုက်တယ်။

မော်ဒယ်က အောက်ပါအဖြေကို ထုတ်လွှင့်လိုက်တယ်-

![Prompt saying "Who was the sole survivor of the Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(အရင်းအမြစ်: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

ဒီဟာက အလွန်ယုံကြည်မှုရှိပြီး အကျိုးရှိသော အဖြေတစ်ခုဖြစ်ပါတယ်။ ဒါပေမယ့် အကောင်းဆုံးအဖြေ မဟုတ်ပါဘူး။ သုတေသနအနည်းငယ်ပဲ လုပ်လိုက်ရင် Titanic အဖြစ်အပျက်မှာ အသက်ရှင်ကျန်ရစ်သူ တစ်ဦးထက်ပိုရှိတယ်ဆိုတာကို သိနိုင်ပါတယ်။ ဒီအကြောင်းအရာကို စတင်လေ့လာနေတဲ့ ကျောင်းသားတစ်ဦးအတွက် ဒီအဖြေဟာ အတိအကျဖြစ်တယ်လို့ ယုံကြည်ပြီး မေးခွန်းမေးဖို့ မလိုအပ်ဘဲ အမှန်တရားအဖြစ် သတ်မှတ်နိုင်ပါတယ်။ ဒီအခြေအနေဟာ AI စနစ်ကို ယုံကြည်စိတ်ချရမှု မရှိစေပြီး ကျွန်တော်တို့ startup ရဲ့ အထင်ကရမှုကိုလည်း အနည်းငယ် ထိခိုက်စေနိုင်ပါတယ်။

LLM တစ်ခုချင်းစီရဲ့ အဆင့်မြှင့်တင်မှုတစ်ခုစီနဲ့အတူ Hallucinations ကို လျှော့ချနိုင်ရေးအတွက် စွမ်းဆောင်ရည်တိုးတက်မှုတွေကို တွေ့မြင်ခဲ့ရပါတယ်။ ဒီတိုးတက်မှုရှိနေတဲ့အချိန်မှာတောင် အက်ပလီကေးရှင်း တည်ဆောက်သူများနှင့် အသုံးပြုသူများအနေနဲ့ ဒီကန့်သတ်ချက်များကို အမြဲသတိထားရပါမယ်။

### အန္တရာယ်ရှိသော အကြောင်းအရာ

LLM က မှားယွင်းသော သို့မဟုတ် အဓိပ္ပါယ်မရှိသော အဖြေများကို ထုတ်လွှင့်သောအခါကို ကျွန်တော်တို့ အရင်ပိုင်းက ဖော်ပြခဲ့ပါတယ်။ မော်ဒယ်က အန္တရာယ်ရှိသော အကြောင်းအရာကို အဖြေထုတ်လွှင့်တဲ့အခါမှာ ကျွန်တော်တို့ သတိထားရမယ့် အခြားအန္တရာယ်တစ်ခုလည်း ရှိပါတယ်။

အန္တရာယ်ရှိသော အကြောင်းအရာကို အောက်ပါအတိုင်း သတ်မှတ်နိုင်ပါတယ်-

- ကိုယ့်ကိုယ်ကို ထိခိုက်စေခြင်း သို့မဟုတ် အုပ်စုတစ်ခုခုကို ထိခိုက်စေခြင်းအတွက် လမ်းညွှန်မှုများပေးခြင်း သို့မဟုတ် အားပေးခြင်း။
- မုန်းတီးမှု သို့မဟုတ် အထင်အမြတ်ထားမှု အကြောင်းအရာများ။
- တိုက်ခိုက်မှု သို့မဟုတ် အကြမ်းဖက်မှု လုပ်ရပ်များကို စီစဉ်ရန် လမ်းညွှန်မှုများပေးခြင်း။
- တရားမဝင်သော အကြောင်းအရာများကို ရှာဖွေခြင်း သို့မဟုတ် တရားမဝင်သော လုပ်ရပ်များကို လုပ်ဆောင်ရန် လမ်းညွှန်မှုများပေးခြင်း။
- လိင်ပိုင်းဆိုင်ရာ အကြောင်းအရာများကို ပြသခြင်း။

ကျွန်တော်တို့ startup အတွက် ကျောင်းသားများအတွက် ဒီအမျိုးအစားအကြောင်းအရာများကို မမြင်ရအောင် သင့်တော်သော ကိရိယာများနှင့် မဟာဗျူဟာများကို သင့်တော်စွာ အသုံးပြုထားဖို့ သေချာစေချင်ပါတယ်။

### တရားမျှတမှုမရှိခြင်း

တရားမျှတမှုကို “AI စနစ်သည် အထင်အမြတ်နှင့် ခွဲခြားမှုကင်းစင်ပြီး လူတိုင်းကို တရားမျှတစွာနှင့် တန်းတူဆက်ဆံခြင်း” ဟု သတ်မှတ်သည်။ Generative AI ရဲ့ ကမ္ဘာမှာ မော်ဒယ်ရဲ့ output က marginalized group တွေရဲ့ အထင်အမြတ်ထားမှုများကို မျှော်လင့်မှုမရှိစေရန် သေချာစေချင်ပါတယ်။

ဒီအမျိုးအစား output တွေဟာ အသုံးပြုသူများအတွက် အကောင်းဆုံး product အတွေ့အကြုံများကို တည်ဆောက်ရာမှာ ဖျက်ဆီးမှုများ ဖြစ်စေသလို လူမှုအဖွဲ့အစည်းအတွက်လည်း ထိခိုက်မှုများ ဖြစ်စေပါတယ်။ အက်ပလီကေးရှင်း တည်ဆောက်သူများအနေနဲ့ Generative AI ကို အသုံးပြုပြီး ဖြေရှင်းချက်များကို တည်ဆောက်ရာမှာ အသုံးပြုသူများရဲ့ ကျယ်ကျယ်ပြန့်ပြန့်နှင့် အမျိုးမျိုးသော အခြေအနေများကို အမြဲစဉ်းစားထားသင့်ပါတယ်။

## Generative AI ကို တာဝန်ရှိရှိ အသုံးပြုနည်း

အခုတော့ Responsible Generative AI ရဲ့ အရေးပါမှုကို သတ်မှတ်ပြီးနောက်၊ AI ဖြေရှင်းချက်များကို တာဝန်ရှိရှိ တည်ဆောက်ဖို့ အဆင့် ၄ ခုကို ကြည့်လိုက်ရအောင်-

![Mitigate Cycle](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.my.png)

### အန္တရာယ်များကို တိုင်းတာခြင်း

ဆော့ဖ်ဝဲကို စမ်းသပ်ရာမှာ အသုံးပြုသူရဲ့ အက်ပလီကေးရှင်းပေါ်မှာ လုပ်ဆောင်မယ့် လုပ်ရပ်များကို စမ်းသပ်ပါတယ်။ ထိုနည်းတူပင် အသုံးပြုသူများ အများဆုံး အသုံးပြုမယ့် prompts များကို စမ်းသပ်ခြင်းက အန္တရာယ်များကို တိုင်းတာဖို့ ကောင်းတဲ့ နည်းလမ်းတစ်ခုဖြစ်ပါတယ်။

ကျွန်တော်တို့ startup ဟာ ပညာရေးထုတ်ကုန်တစ်ခုကို တည်ဆောက်နေတဲ့အတွက် ပညာရေးနှင့်ဆက်စပ်တဲ့ prompts များစာရင်းကို ပြင်ဆင်ထားသင့်ပါတယ်။ ဒါဟာ အတန်းအပေါ်တစ်ခုခု၊ သမိုင်းအချက်အလက်များနှင့် ကျောင်းသားဘဝအကြောင်း prompts များကို ဖုံးအုပ်နိုင်ဖို့ ဖြစ်ပါတယ်။

### အန္တရာယ်များကို လျှော့ချခြင်း

အခုတော့ မော်ဒယ်နှင့် output ရဲ့ အန္တရာယ်များကို ကာကွယ်ခြင်း သို့မဟုတ် ကန့်သတ်ခြင်းနည်းလမ်းများကို ရှာဖွေဖို့ အချိန်ရောက်ပါပြီ။ ဒီဟာကို အလွှာ ၄ ခုအနေနဲ့ ကြည့်နိုင်ပါတယ်-

![Mitigation Layers](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.my.png)

- **Model**. သင့်တော်သော use case အတွက် သင့်တော်သော မော်ဒယ်ကို ရွေးချယ်ခြင်း။ GPT-4 ကဲ့သို့သော ကြီးမားပြီး ရှုပ်ထွေးသော မော်ဒယ်များဟာ သေးငယ်ပြီး သတ်မှတ်ထားသော use case များတွင် အန္တရာယ်ရှိသော အကြောင်းအရာများကို ဖြစ်စေနိုင်ပါတယ်။ သင့် training data ကို အသုံးပြုပြီး fine-tune လုပ်ခြင်းကလည်း အန္တရာယ်ရှိသော အကြောင်းအရာများကို လျှော့ချစေနိုင်ပါတယ်။

- **Safety System**. Safety system ဆိုတာ မော်ဒယ်ကို စနစ်ပေါ်မှာ တင်ဆောင်ရာမှာ အန္တရာယ်များကို လျှော့ချနိုင်စေသော ကိရိယာများနှင့် configuration များဖြစ်သည်။ ဥပမာအားဖြင့် Azure OpenAI service ရဲ့ content filtering system ကို ဖော်ပြနိုင်ပါတယ်။ စနစ်များဟာ jailbreak attacks နှင့် bots တွေက request လုပ်မှုများကိုလည်း ရှာဖွေသိရှိနိုင်ဖို့ လိုအပ်ပါတယ်။

- **Metaprompt**. Metaprompts နှင့် grounding ဟာ မော်ဒယ်ကို သတ်မှတ်ထားသော အပြုအမူများနှင့် အချက်အလက်များအပေါ် အတိအကျ သို့မဟုတ် ကန့်သတ်နိုင်စေသော နည်းလမ်းများဖြစ်ပါတယ်။ ဒီဟာက မော်ဒယ်ရဲ့ အကန့်အသတ်များကို သတ်မှတ်ဖို့ system inputs ကို အသုံးပြုခြင်းဖြစ်နိုင်ပါတယ်။ ထို့အပြင် စနစ်ရဲ့ scope သို့မဟုတ် domain နှင့် ပိုမိုသက်ဆိုင်သော output များကို ပေးစွမ်းခြင်းဖြစ်နိုင်ပါတယ်။

RAG (Retrieval Augmented Generation) ကဲ့သို့သော နည်းလမ်းများကို အသုံးပြုခြင်းကလည်း မော်ဒယ်ကို ယုံကြည်စိတ်ချရသော အရင်းအမြစ်များမှသာ အချက်အလက်များကို ရယူစေခြင်းဖြစ်ပါတယ်။ [search applications တည်ဆောက်ခြင်း](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst) အတွက် သင်ခန်းစာတစ်ခုလည်း ဒီသင်တန်းမှာ ရှိပါတယ်။

- **User Experience**. နောက်ဆုံးအလွှာက အသုံးပြုသူဟာ မော်ဒယ်နဲ့ တိုက်ရိုက် အပြန်အလှန်လုပ်ဆောင်မှုကို ကျွန်တော်တို့ application ရဲ့ interface မှတဆင့် ပြုလုပ်တဲ့နေရာဖြစ်ပါတယ်။ ဒီနည်းလမ်းနဲ့ အသုံးပြုသူက မော်ဒယ်ကို ပေးပို့နိုင်တဲ့ input အမျိုးအစားများကို ကန့်သတ်နိုင်သလို အသုံးပြုသူကို ပြသတဲ့ စာသား သို့မဟုတ် ပုံများကိုလည်း ကန့်သတ်နိုင်ပါတယ်။ AI application ကို တင်ဆောင်ရာမှာ ကျွန်တော်တို့ Generative AI application ရဲ့ အတတ်နိုင်မှုများနှင့် မတတ်နိုင်သော အချက်များကိုလည်း ထင်ရှားစွာ ဖော်ပြရပါမယ်။

[AI Applications အတွက် UX တီထွင်ခြင်း](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst) အတွက် သင်ခန်းစာတစ်ခုလည်း ကျွန်တော်တို့မှာ ရှိပါတယ်။

- **Evaluate model**. LLMs နဲ့ အလုပ်လုပ်ရတာဟာ အခက်အခဲရှိနိုင်ပါတယ်၊ အကြောင်းက မော်ဒယ်ကို training လုပ်ထားတဲ့ data ကို ကျွန်တော်တို့ အမြဲထိန်းချုပ်နိုင်မှာ မဟုတ်လို့ပါ။ သို့သော်လည်း မော်ဒယ်ရဲ့ စွမ်းဆောင်ရည်နှင့် output များကို အမြဲတမ်း အကဲဖြတ်ရပါမယ်။ မော်ဒယ်

---

**အကြောင်းကြားချက်**:  
ဤစာရွက်စာတမ်းကို AI ဘာသာပြန်ဝန်ဆောင်မှု [Co-op Translator](https://github.com/Azure/co-op-translator) ကို အသုံးပြု၍ ဘာသာပြန်ထားပါသည်။ ကျွန်ုပ်တို့သည် တိကျမှုအတွက် ကြိုးစားနေသော်လည်း အလိုအလျောက် ဘာသာပြန်မှုများတွင် အမှားများ သို့မဟုတ် မမှန်ကန်မှုများ ပါဝင်နိုင်သည်ကို သတိပြုပါ။ မူရင်းဘာသာစကားဖြင့် ရေးသားထားသော စာရွက်စာတမ်းကို အာဏာတရားရှိသော အရင်းအမြစ်အဖြစ် သတ်မှတ်သင့်ပါသည်။ အရေးကြီးသော အချက်အလက်များအတွက် လူသားပညာရှင်များမှ ဘာသာပြန်မှုကို အကြံပြုပါသည်။ ဤဘာသာပြန်မှုကို အသုံးပြုခြင်းမှ ဖြစ်ပေါ်လာသော အလွဲအမှားများ သို့မဟုတ် အနားလွဲမှုများအတွက် ကျွန်ုပ်တို့သည် တာဝန်မယူပါ။