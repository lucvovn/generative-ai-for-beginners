<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df98b2c59f87d8543135301e87969f70",
  "translation_date": "2025-10-11T11:17:21+00:00",
  "source_file": "15-rag-and-vector-databases/data/own_framework.md",
  "language_code": "et"
}
-->
# Sissejuhatus tehisn√§rviv√µrkudesse. Mitmekihiline perceptron

Eelmises osas √µppisite tundma k√µige lihtsamat tehisn√§rviv√µrgu mudelit ‚Äì √ºhekihilist perceptronit, mis on lineaarne kahe klassi klassifitseerimise mudel.

Selles osas laiendame seda mudelit paindlikumaks raamistikuks, mis v√µimaldab:

* teha **mitme klassi klassifitseerimist** lisaks kahe klassi klassifitseerimisele
* lahendada **regressiooniprobleeme** lisaks klassifitseerimisele
* eristada klasse, mis ei ole lineaarselt eristatavad

Samuti arendame v√§lja oma modulaarse raamistiku Pythonis, mis v√µimaldab meil luua erinevaid tehisn√§rviv√µrgu arhitektuure.

## Masin√µppe formaliseerimine

Alustame masin√µppe probleemi formaliseerimisest. Oletame, et meil on treeningandmestik **X** koos siltidega **Y**, ja peame looma mudeli *f*, mis teeb k√µige t√§psemad ennustused. Ennustuste kvaliteeti m√µ√µdetakse **kaofunktsiooni** &lagran; abil. Sageli kasutatakse j√§rgmisi kaofunktsioone:

* Regressiooniprobleemi puhul, kui peame ennustama arvu, v√µime kasutada **absoluutset viga** &sum;<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>| v√µi **ruutviga** &sum;<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup>
* Klassifitseerimise puhul kasutame **0-1 kadu** (mis sisuliselt on sama mis mudeli **t√§psus**) v√µi **logistilist kadu**.

√úhekihilise perceptroni puhul oli funktsioon *f* defineeritud lineaarse funktsioonina *f(x)=wx+b* (kus *w* on kaalude maatriks, *x* on sisendite tunnuste vektor ja *b* on nihkevektor). Erinevate tehisn√§rviv√µrgu arhitektuuride puhul v√µib see funktsioon olla keerukama kujuga.

> Klassifitseerimise puhul on sageli soovitav saada v√µrgu v√§ljundina klasside t√µen√§osused. Arvude teisendamiseks t√µen√§osusteks (nt v√§ljundi normaliseerimiseks) kasutame sageli **softmax** funktsiooni &sigma;, ja funktsioon *f* muutub *f(x)=&sigma;(wx+b)*

√úlaltoodud *f* definitsioonis nimetatakse *w* ja *b* **parameetriteks** &theta;=‚ü®*w,b*‚ü©. Arvestades andmestikku ‚ü®**X**,**Y**‚ü©, saame arvutada kogu andmestiku vea parameetrite &theta; funktsioonina.

> ‚úÖ **Tehisn√§rviv√µrgu treenimise eesm√§rk on minimeerida viga, muutes parameetreid &theta;**

## Gradientlanguse optimeerimine

On olemas tuntud funktsiooni optimeerimise meetod, mida nimetatakse **gradientlanguseks**. Idee seisneb selles, et saame arvutada kaofunktsiooni tuletise (mitmem√µ√µtmelisel juhul nimetatakse seda **gradiendiks**) parameetrite suhtes ja muuta parameetreid nii, et viga v√§heneks. Seda saab formaliseerida j√§rgmiselt:

* Algv√§√§rtusta parameetrid juhuslike v√§√§rtustega w<sup>(0)</sup>, b<sup>(0)</sup>
* Korda j√§rgmist sammu mitu korda:
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-&eta;&part;&lagran;/&part;w
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-&eta;&part;&lagran;/&part;b

Treeningu ajal arvutatakse optimeerimissammud kogu andmestikku arvesse v√µttes (pidage meeles, et kadu arvutatakse k√µigi treeningn√§idete summa p√µhjal). Kuid reaalses elus v√µtame andmestikust v√§ikeseid osi, mida nimetatakse **minipartiideks**, ja arvutame gradiendid andmealamkogumi p√µhjal. Kuna alamkogum valitakse iga kord juhuslikult, nimetatakse sellist meetodit **stohhastiliseks gradientlanguseks** (SGD).

## Mitmekihilised perceptronid ja tagasilevik

√úhekihiline v√µrk, nagu me eespool n√§gime, suudab klassifitseerida lineaarselt eristatavaid klasse. Rikkalikuma mudeli loomiseks saame kombineerida mitu v√µrgu kihti. Matemaatiliselt t√§hendaks see, et funktsioon *f* oleks keerukama kujuga ja arvutataks mitmes etapis:
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>&alpha;(z<sub>1</sub>)+b<sub>2</sub>
* f = &sigma;(z<sub>2</sub>)

Siin on &alpha; **mittelineaarne aktivatsioonifunktsioon**, &sigma; on softmax-funktsioon ja parameetrid &theta;=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*>.

Gradientlanguse algoritm j√§√§b samaks, kuid gradientide arvutamine muutub keerulisemaks. Arvestades ahel-diferentseerimise reeglit, saame tuletised arvutada j√§rgmiselt:

* &part;&lagran;/&part;w<sub>2</sub> = (&part;&lagran;/&part;&sigma;)(&part;&sigma;/&part;z<sub>2</sub>)(&part;z<sub>2</sub>/&part;w<sub>2</sub>)
* &part;&lagran;/&part;w<sub>1</sub> = (&part;&lagran;/&part;&sigma;)(&part;&sigma;/&part;z<sub>2</sub>)(&part;z<sub>2</sub>/&part;&alpha;)(&part;&alpha;/&part;z<sub>1</sub>)(&part;z<sub>1</sub>/&part;w<sub>1</sub>)

> ‚úÖ Ahel-diferentseerimise reeglit kasutatakse kaofunktsiooni tuletiste arvutamiseks parameetrite suhtes.

Pange t√§hele, et k√µigi nende avaldiste vasakpoolne osa on sama, ja seega saame tuletised t√µhusalt arvutada, alustades kaofunktsioonist ja liikudes "tagasi" l√§bi arvutusgraafi. Seet√µttu nimetatakse mitmekihilise perceptroni treenimise meetodit **tagasilevikuks** v√µi 'backprop'.

> TODO: pildi viide

> ‚úÖ Tagasilevikku k√§sitleme palju √ºksikasjalikumalt meie n√§idisnotebookis.  

## Kokkuv√µte

Selles √µppetunnis ehitasime oma tehisn√§rviv√µrgu raamistiku ja kasutasime seda lihtsa kahem√µ√µtmelise klassifitseerimis√ºlesande lahendamiseks.

## üöÄ V√§ljakutse

Kaasasolevas notebookis rakendate oma raamistiku mitmekihiliste perceptronite loomiseks ja treenimiseks. N√§ete √ºksikasjalikult, kuidas kaasaegsed tehisn√§rviv√µrgud t√∂√∂tavad.

J√§tkake OwnFramework notebookiga ja t√∂√∂tage see l√§bi.

## √úlevaade ja iseseisev √µppimine

Tagasilevik on tehisintellekti ja masin√µppe valdkonnas levinud algoritm, mida tasub p√µhjalikumalt uurida.

## √úlesanne

Selles laboris palutakse teil kasutada selles √µppetunnis loodud raamistikku MNIST k√§sitsi kirjutatud numbrite klassifitseerimise lahendamiseks.

* Juhised
* Notebook

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud AI t√µlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi p√º√ºame tagada t√§psust, palume arvestada, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tulenevate arusaamatuste v√µi valesti t√µlgenduste eest.