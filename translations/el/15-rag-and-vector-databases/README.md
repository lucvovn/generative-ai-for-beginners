<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b4b0266fbadbba7ded891b6485adc66d",
  "translation_date": "2025-10-17T18:21:18+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "el"
}
-->
# Ανάκτηση Ενισχυμένης Γενετικής (RAG) και Βάσεις Δεδομένων Διανυσμάτων

[![Ανάκτηση Ενισχυμένης Γενετικής (RAG) και Βάσεις Δεδομένων Διανυσμάτων](../../../translated_images/15-lesson-banner.ac49e59506175d4fc6ce521561dab2f9ccc6187410236376cfaed13cde371b90.el.png)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

Στο μάθημα για τις εφαρμογές αναζήτησης, μάθαμε σύντομα πώς να ενσωματώσετε τα δικά σας δεδομένα σε Μεγάλα Γλωσσικά Μοντέλα (LLMs). Σε αυτό το μάθημα, θα εμβαθύνουμε περαιτέρω στις έννοιες της ενσωμάτωσης των δεδομένων σας στην εφαρμογή LLM, στους μηχανισμούς της διαδικασίας και στις μεθόδους αποθήκευσης δεδομένων, συμπεριλαμβανομένων των ενσωματώσεων και του κειμένου.

> **Βίντεο Σύντομα Διαθέσιμο**

## Εισαγωγή

Σε αυτό το μάθημα θα καλύψουμε τα εξής:

- Εισαγωγή στο RAG, τι είναι και γιατί χρησιμοποιείται στην τεχνητή νοημοσύνη (AI).

- Κατανόηση τι είναι οι βάσεις δεδομένων διανυσμάτων και δημιουργία μιας για την εφαρμογή μας.

- Ένα πρακτικό παράδειγμα για το πώς να ενσωματώσετε το RAG σε μια εφαρμογή.

## Στόχοι Μάθησης

Μετά την ολοκλήρωση αυτού του μαθήματος, θα μπορείτε να:

- Εξηγήσετε τη σημασία του RAG στην ανάκτηση και επεξεργασία δεδομένων.

- Ρυθμίσετε μια εφαρμογή RAG και να ενσωματώσετε τα δεδομένα σας σε ένα LLM.

- Ενσωματώσετε αποτελεσματικά το RAG και τις Βάσεις Δεδομένων Διανυσμάτων σε Εφαρμογές LLM.

## Το Σενάριό μας: Ενίσχυση των LLMs με τα δικά μας δεδομένα

Για αυτό το μάθημα, θέλουμε να προσθέσουμε τις δικές μας σημειώσεις στην εκπαιδευτική startup, η οποία επιτρέπει στο chatbot να αποκτήσει περισσότερες πληροφορίες για τα διάφορα θέματα. Χρησιμοποιώντας τις σημειώσεις που έχουμε, οι μαθητές θα μπορούν να μελετούν καλύτερα και να κατανοούν τα διάφορα θέματα, διευκολύνοντας την επανάληψη για τις εξετάσεις τους. Για να δημιουργήσουμε το σενάριό μας, θα χρησιμοποιήσουμε:

- `Azure OpenAI:` το LLM που θα χρησιμοποιήσουμε για να δημιουργήσουμε το chatbot μας

- `Μάθημα για αρχάριους στην Τεχνητή Νοημοσύνη για Νευρωνικά Δίκτυα:` αυτά θα είναι τα δεδομένα που θα ενσωματώσουμε στο LLM μας

- `Azure AI Search` και `Azure Cosmos DB:` βάση δεδομένων διανυσμάτων για την αποθήκευση των δεδομένων μας και τη δημιουργία ενός ευρετηρίου αναζήτησης

Οι χρήστες θα μπορούν να δημιουργούν πρακτικά κουίζ από τις σημειώσεις τους, κάρτες επανάληψης και να τις συνοψίζουν σε συνοπτικές επισκοπήσεις. Για να ξεκινήσουμε, ας δούμε τι είναι το RAG και πώς λειτουργεί:

## Ανάκτηση Ενισχυμένης Γενετικής (RAG)

Ένα chatbot που βασίζεται σε LLM επεξεργάζεται τις προτροπές των χρηστών για να δημιουργήσει απαντήσεις. Είναι σχεδιασμένο να είναι διαδραστικό και να αλληλεπιδρά με τους χρήστες σε ένα ευρύ φάσμα θεμάτων. Ωστόσο, οι απαντήσεις του περιορίζονται στο πλαίσιο που παρέχεται και στα βασικά δεδομένα εκπαίδευσής του. Για παράδειγμα, η γνώση του GPT-4 περιορίζεται μέχρι τον Σεπτέμβριο του 2021, πράγμα που σημαίνει ότι δεν έχει γνώση γεγονότων που έχουν συμβεί μετά από αυτήν την περίοδο. Επιπλέον, τα δεδομένα που χρησιμοποιούνται για την εκπαίδευση των LLMs εξαιρούν εμπιστευτικές πληροφορίες όπως προσωπικές σημειώσεις ή το εγχειρίδιο προϊόντων μιας εταιρείας.

### Πώς λειτουργούν τα RAGs (Ανάκτηση Ενισχυμένης Γενετικής)

![σχέδιο που δείχνει πώς λειτουργούν τα RAGs](../../../translated_images/how-rag-works.f5d0ff63942bd3a638e7efee7a6fce7f0787f6d7a1fca4e43f2a7a4d03cde3e0.el.png)

Ας υποθέσουμε ότι θέλετε να αναπτύξετε ένα chatbot που δημιουργεί κουίζ από τις σημειώσεις σας, θα χρειαστείτε μια σύνδεση με τη βάση γνώσεων. Εδώ έρχεται το RAG να σας βοηθήσει. Τα RAGs λειτουργούν ως εξής:

- **Βάση γνώσεων:** Πριν από την ανάκτηση, αυτά τα έγγραφα πρέπει να εισαχθούν και να προεπεξεργαστούν, συνήθως διασπώντας μεγάλα έγγραφα σε μικρότερα τμήματα, μετατρέποντάς τα σε ενσωματώσεις κειμένου και αποθηκεύοντάς τα σε μια βάση δεδομένων.

- **Ερώτηση χρήστη:** ο χρήστης θέτει μια ερώτηση

- **Ανάκτηση:** Όταν ο χρήστης θέτει μια ερώτηση, το μοντέλο ενσωμάτωσης ανακτά σχετικές πληροφορίες από τη βάση γνώσεων μας για να παρέχει περισσότερο πλαίσιο που θα ενσωματωθεί στην προτροπή.

- **Ενισχυμένη Γενετική:** το LLM βελτιώνει την απάντησή του βάσει των δεδομένων που ανακτήθηκαν. Επιτρέπει η απάντηση που δημιουργείται να βασίζεται όχι μόνο στα δεδομένα εκπαίδευσης αλλά και σε σχετικές πληροφορίες από το πρόσθετο πλαίσιο. Τα δεδομένα που ανακτήθηκαν χρησιμοποιούνται για την ενίσχυση των απαντήσεων του LLM. Το LLM επιστρέφει στη συνέχεια μια απάντηση στην ερώτηση του χρήστη.

![σχέδιο που δείχνει την αρχιτεκτονική των RAGs](../../../translated_images/encoder-decode.f2658c25d0eadee2377bb28cf3aee8b67aa9249bf64d3d57bb9be077c4bc4e1a.el.png)

Η αρχιτεκτονική των RAGs υλοποιείται χρησιμοποιώντας μετασχηματιστές που αποτελούνται από δύο μέρη: έναν κωδικοποιητή και έναν αποκωδικοποιητή. Για παράδειγμα, όταν ένας χρήστης θέτει μια ερώτηση, το κείμενο εισόδου 'κωδικοποιείται' σε διανύσματα που καταγράφουν τη σημασία των λέξεων και τα διανύσματα 'αποκωδικοποιούνται' στο ευρετήριο εγγράφων μας και δημιουργούν νέο κείμενο βάσει της ερώτησης του χρήστη. Το LLM χρησιμοποιεί τόσο ένα μοντέλο κωδικοποιητή-αποκωδικοποιητή για να δημιουργήσει την έξοδο.

Δύο προσεγγίσεις κατά την υλοποίηση του RAG σύμφωνα με την προτεινόμενη εργασία: [Retrieval-Augmented Generation for Knowledge intensive NLP (natural language processing software) Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) είναι:

- **_RAG-Sequence_** χρησιμοποιώντας ανακτημένα έγγραφα για να προβλέψει την καλύτερη δυνατή απάντηση σε μια ερώτηση χρήστη

- **RAG-Token** χρησιμοποιώντας έγγραφα για να δημιουργήσει το επόμενο token και στη συνέχεια να τα ανακτήσει για να απαντήσει στην ερώτηση του χρήστη

### Γιατί να χρησιμοποιήσετε RAGs;

- **Πλούτος πληροφοριών:** εξασφαλίζει ότι οι απαντήσεις κειμένου είναι ενημερωμένες και τρέχουσες. Επομένως, βελτιώνει την απόδοση σε εργασίες συγκεκριμένου τομέα, αποκτώντας πρόσβαση στην εσωτερική βάση γνώσεων.

- Μειώνει την κατασκευή πληροφοριών χρησιμοποιώντας **επαληθεύσιμα δεδομένα** στη βάση γνώσεων για να παρέχει πλαίσιο στις ερωτήσεις των χρηστών.

- Είναι **οικονομικά αποδοτικό** καθώς είναι πιο οικονομικό σε σύγκριση με την προσαρμογή ενός LLM.

## Δημιουργία βάσης γνώσεων

Η εφαρμογή μας βασίζεται στα προσωπικά μας δεδομένα, δηλαδή το μάθημα για Νευρωνικά Δίκτυα από το πρόγραμμα σπουδών AI For Beginners.

### Βάσεις Δεδομένων Διανυσμάτων

Μια βάση δεδομένων διανυσμάτων, σε αντίθεση με τις παραδοσιακές βάσεις δεδομένων, είναι μια εξειδικευμένη βάση δεδομένων σχεδιασμένη να αποθηκεύει, να διαχειρίζεται και να αναζητά ενσωματωμένα διανύσματα. Αποθηκεύει αριθμητικές αναπαραστάσεις εγγράφων. Η διάσπαση δεδομένων σε αριθμητικές ενσωματώσεις διευκολύνει το σύστημα AI μας να κατανοήσει και να επεξεργαστεί τα δεδομένα.

Αποθηκεύουμε τις ενσωματώσεις μας σε βάσεις δεδομένων διανυσμάτων καθώς τα LLMs έχουν όριο στον αριθμό των tokens που δέχονται ως είσοδο. Δεδομένου ότι δεν μπορείτε να περάσετε όλες τις ενσωματώσεις σε ένα LLM, θα χρειαστεί να τις διασπάσετε σε τμήματα και όταν ένας χρήστης θέτει μια ερώτηση, οι ενσωματώσεις που μοιάζουν περισσότερο με την ερώτηση θα επιστραφούν μαζί με την προτροπή. Η διάσπαση επίσης μειώνει το κόστος στον αριθμό των tokens που περνούν μέσω ενός LLM.

Μερικές δημοφιλείς βάσεις δεδομένων διανυσμάτων περιλαμβάνουν Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant και DeepLake. Μπορείτε να δημιουργήσετε ένα μοντέλο Azure Cosmos DB χρησιμοποιώντας το Azure CLI με την ακόλουθη εντολή:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Από κείμενο σε ενσωματώσεις

Πριν αποθηκεύσουμε τα δεδομένα μας, θα χρειαστεί να τα μετατρέψουμε σε ενσωματώσεις διανυσμάτων πριν αποθηκευτούν στη βάση δεδομένων. Εάν εργάζεστε με μεγάλα έγγραφα ή μακροσκελή κείμενα, μπορείτε να τα διασπάσετε βάσει ερωτήσεων που αναμένετε. Η διάσπαση μπορεί να γίνει σε επίπεδο πρότασης ή σε επίπεδο παραγράφου. Δεδομένου ότι η διάσπαση αντλεί νοήματα από τις λέξεις γύρω τους, μπορείτε να προσθέσετε κάποιο άλλο πλαίσιο σε ένα τμήμα, για παράδειγμα, προσθέτοντας τον τίτλο του εγγράφου ή συμπεριλαμβάνοντας κάποιο κείμενο πριν ή μετά το τμήμα. Μπορείτε να διασπάσετε τα δεδομένα ως εξής:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Μόλις διασπαστούν, μπορούμε στη συνέχεια να ενσωματώσουμε το κείμενό μας χρησιμοποιώντας διαφορετικά μοντέλα ενσωμάτωσης. Μερικά μοντέλα που μπορείτε να χρησιμοποιήσετε περιλαμβάνουν: word2vec, ada-002 από την OpenAI, Azure Computer Vision και πολλά άλλα. Η επιλογή ενός μοντέλου θα εξαρτηθεί από τις γλώσσες που χρησιμοποιείτε, τον τύπο περιεχομένου που κωδικοποιείται (κείμενο/εικόνες/ήχος), το μέγεθος της εισόδου που μπορεί να κωδικοποιήσει και το μήκος της εξόδου ενσωμάτωσης.

Ένα παράδειγμα ενσωματωμένου κειμένου χρησιμοποιώντας το μοντέλο `text-embedding-ada-002` της OpenAI είναι:
![μια ενσωμάτωση της λέξης γάτα](../../../translated_images/cat.74cbd7946bc9ca380a8894c4de0c706a4f85b16296ffabbf52d6175df6bf841e.el.png)

## Ανάκτηση και Αναζήτηση Διανυσμάτων

Όταν ένας χρήστης θέτει μια ερώτηση, ο ανακτητής τη μετατρέπει σε ένα διάνυσμα χρησιμοποιώντας τον κωδικοποιητή ερωτήσεων, στη συνέχεια αναζητά στο ευρετήριο εγγράφων μας για σχετικά διανύσματα στο έγγραφο που σχετίζονται με την είσοδο. Μόλις ολοκληρωθεί, μετατρέπει τόσο το διάνυσμα εισόδου όσο και τα διανύσματα εγγράφων σε κείμενο και τα περνά μέσω του LLM.

### Ανάκτηση

Η ανάκτηση συμβαίνει όταν το σύστημα προσπαθεί να βρει γρήγορα τα έγγραφα από το ευρετήριο που ικανοποιούν τα κριτήρια αναζήτησης. Ο στόχος του ανακτητή είναι να πάρει έγγραφα που θα χρησιμοποιηθούν για να παρέχουν πλαίσιο και να ενσωματώσουν το LLM στα δεδομένα σας.

Υπάρχουν διάφοροι τρόποι για να πραγματοποιήσετε αναζήτηση μέσα στη βάση δεδομένων μας, όπως:

- **Αναζήτηση λέξεων-κλειδιών** - χρησιμοποιείται για αναζητήσεις κειμένου

- **Σημασιολογική αναζήτηση** - χρησιμοποιεί τη σημασιολογική σημασία των λέξεων

- **Αναζήτηση διανυσμάτων** - μετατρέπει έγγραφα από κείμενο σε αναπαραστάσεις διανυσμάτων χρησιμοποιώντας μοντέλα ενσωμάτωσης. Η ανάκτηση θα γίνει με την ερώτηση των εγγράφων των οποίων οι αναπαραστάσεις διανυσμάτων είναι πιο κοντά στην ερώτηση του χρήστη.

- **Υβριδική** - ένας συνδυασμός τόσο της αναζήτησης λέξεων-κλειδιών όσο και της αναζήτησης διανυσμάτων.

Μια πρόκληση με την ανάκτηση προκύπτει όταν δεν υπάρχει παρόμοια απάντηση στην ερώτηση στη βάση δεδομένων, το σύστημα θα επιστρέψει την καλύτερη πληροφορία που μπορεί να βρει, ωστόσο, μπορείτε να χρησιμοποιήσετε τακτικές όπως να ορίσετε τη μέγιστη απόσταση για τη συνάφεια ή να χρησιμοποιήσετε υβριδική αναζήτηση που συνδυάζει τόσο λέξεις-κλειδιά όσο και αναζήτηση διανυσμάτων. Σε αυτό το μάθημα θα χρησιμοποιήσουμε υβριδική αναζήτηση, έναν συνδυασμό τόσο αναζήτησης διανυσμάτων όσο και λέξεων-κλειδιών. Θα αποθηκεύσουμε τα δεδομένα μας σε ένα dataframe με στήλες που περιέχουν τα τμήματα καθώς και τις ενσωματώσεις.

### Ομοιότητα Διανυσμάτων

Ο ανακτητής θα αναζητήσει στη βάση γνώσεων για ενσωματώσεις που είναι κοντά μεταξύ τους, τον πλησιέστερο γείτονα, καθώς είναι κείμενα που είναι παρόμοια. Στο σενάριο που ένας χρήστης θέτει μια ερώτηση, αυτή πρώτα ενσωματώνεται και στη συνέχεια αντιστοιχείται με παρόμοιες ενσωματώσεις. Η κοινή μέτρηση που χρησιμοποιείται για να βρεθεί πόσο παρόμοια είναι διαφορετικά διανύσματα είναι η συνημίτονη ομοιότητα, η οποία βασίζεται στη γωνία μεταξύ δύο διανυσμάτων.

Μπορούμε να μετρήσουμε την ομοιότητα χρησιμοποιώντας άλλες εναλλακτικές όπως η Ευκλείδεια απόσταση, η οποία είναι η ευθεία γραμμή μεταξύ των άκρων των διανυσμάτων, και το εσωτερικό γινόμενο, το οποίο μετρά το άθροισμα των γινομένων των αντίστοιχων στοιχείων δύο διανυσμάτων.

### Ευρετήριο Αναζήτησης

Όταν κάνουμε ανάκτηση, θα χρειαστεί να δημιουργήσουμε ένα ευρετήριο αναζήτησης για τη βάση γνώσεων μας πριν πραγματοποιήσουμε αναζήτηση. Ένα ευρετήριο θα αποθηκεύσει τις ενσωματώσεις μας και μπορεί να ανακτήσει γρήγορα τα πιο παρόμοια τμήματα ακόμα και σε μια μεγάλη βάση δεδομένων. Μπορούμε να δημιουργήσουμε το ευρετήριο μας τοπικά χρησιμοποιώντας:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Επανακατάταξη

Μόλις έχετε ερωτήσει τη βάση δεδομένων, μπορεί να χρειαστεί να ταξινομήσετε τα αποτελέσματα από τα πιο σχετικά. Ένα LLM επανακατάταξης χρησιμοποιεί Μηχανική Μάθηση για να βελτιώσει τη συνάφεια των αποτελεσμάτων αναζήτησης, ταξινομώντας τα από τα πιο σχετικά. Χρησιμοποιώντας το Azure AI Search, η επανακατάταξη γίνεται αυτόματα για εσάς χρησιμοποιώντας έναν σημασιολογικό επανακατατάκτη. Ένα παράδειγμα για το πώς λειτουργεί η επανακατάταξη χρησιμοποιώντας πλησιέστερους γείτονες:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Συνδυάζοντας τα όλα

Το τελευταίο βήμα είναι να προσθέσουμε το LLM μας στο μείγμα για να μπορέσουμε να λάβουμε απαντήσεις που βασίζονται στα δεδομένα μας. Μπορούμε να το υλοποιήσουμε ως εξής:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Αξιολόγηση της εφαρμογής μας

### Μετρικές Αξιολόγησης

- Ποιότητα των απαντήσεων που παρέχονται, εξασφα

---

**Αποποίηση ευθύνης**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που καταβάλλουμε προσπάθειες για ακρίβεια, παρακαλούμε να έχετε υπόψη ότι οι αυτοματοποιημένες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα θα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή εσφαλμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.