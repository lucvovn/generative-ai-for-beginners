{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# மெட்டா குடும்ப மாடல்களுடன் கட்டமைத்தல்\n",
    "\n",
    "## அறிமுகம்\n",
    "\n",
    "இந்த பாடத்தில் நாம் கற்றுக்கொள்ள போவது:\n",
    "\n",
    "- மெட்டா குடும்பத்தின் இரண்டு முக்கிய மாடல்களை ஆராய்வது - Llama 3.1 மற்றும் Llama 3.2  \n",
    "- ஒவ்வொரு மாடலின் பயன்பாடுகள் மற்றும் சூழல்களைப் புரிந்துகொள்வது  \n",
    "- ஒவ்வொரு மாடலின் தனித்துவமான அம்சங்களை காட்டும் குறியீட்டு மாதிரி  \n",
    "\n",
    "## மெட்டா குடும்ப மாடல்கள்\n",
    "\n",
    "இந்த பாடத்தில், மெட்டா குடும்பத்திலிருந்து அல்லது \"Llama Herd\"-இல் இருந்து இரண்டு மாடல்களை ஆராய்வோம் - Llama 3.1 மற்றும் Llama 3.2  \n",
    "\n",
    "இந்த மாடல்கள் பல்வேறு வகைகளில் கிடைக்கின்றன மற்றும் Github Model சந்தையில் கிடைக்கின்றன. AI மாடல்களுடன் [prototype செய்ய Github Models](https://docs.github.com/en/github-models/prototyping-with-ai-models?WT.mc_id=academic-105485-koreyst) பயன்படுத்துவது பற்றிய கூடுதல் விவரங்கள் இங்கே உள்ளன.\n",
    "\n",
    "மாடல் வகைகள்:  \n",
    "- Llama 3.1 - 70B Instruct  \n",
    "- Llama 3.1 - 405B Instruct  \n",
    "- Llama 3.2 - 11B Vision Instruct  \n",
    "- Llama 3.2 - 90B Vision Instruct  \n",
    "\n",
    "*குறிப்பு: Llama 3 Github Models-இல் கிடைக்கிறது, ஆனால் இந்த பாடத்தில் அது கையாளப்படாது.*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.1\n",
    "\n",
    "405 பில்லியன் அளவிலான பராமீட்டர்களுடன், Llama 3.1 திறந்த மூல LLM வகையில் அடங்குகிறது.\n",
    "\n",
    "Llama 3.1, முந்தைய வெளியீடான Llama 3-இன் மேம்படுத்தப்பட்ட வடிவமாகும், இது கீழ்க்கண்டவற்றை வழங்குகிறது:\n",
    "\n",
    "- பெரிய சூழல் சாளரம் - 128k டோக்கன்கள் vs 8k டோக்கன்கள்  \n",
    "- அதிகபட்ச வெளியீடு டோக்கன்கள் - 4096 vs 2048  \n",
    "- மேம்பட்ட பன்மொழி ஆதரவு - பயிற்சி டோக்கன்களின் அதிகரிப்பின் காரணமாக  \n",
    "\n",
    "இவை Llama 3.1-ஐ GenAI பயன்பாடுகளை உருவாக்கும்போது மேலும் சிக்கலான பயன்பாடுகளை கையாள உதவுகிறது, அதில் அடங்கும்:  \n",
    "- இயல்நிலை செயல்பாடு அழைப்புகள் - LLM வேலைப்பாடுகளுக்கு வெளியே வெளிப்புற கருவிகள் மற்றும் செயல்பாடுகளை அழைக்கும் திறன்  \n",
    "- மேம்பட்ட RAG செயல்திறன் - அதிக சூழல் சாளரத்தின் காரணமாக  \n",
    "- செயற்கை தரவுத் உருவாக்கம் - நுணுக்கமாக அமைக்கும் போன்ற பணிகளுக்கு பயனுள்ள தரவுகளை உருவாக்கும் திறன்  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### இயற்கை செயல்பாடு அழைப்புகள்\n",
    "\n",
    "Llama 3.1 செயல்பாடுகள் அல்லது கருவிகளை அழைப்பதில் மேலும் திறமையாக செயல்பட하도록 நன்றாகச் சீரமைக்கப்பட்டுள்ளது. இது இரண்டு உள்ளமைக்கப்பட்ட கருவிகளை கொண்டுள்ளது, அவற்றை பயனர் வழங்கும் உத்தரவின் அடிப்படையில் பயன்படுத்த வேண்டியதென மாடல் அடையாளம் காணும். இந்த கருவிகள்:\n",
    "\n",
    "- **Brave Search** - வலை தேடலின் மூலம் வானிலை போன்ற சமீபத்திய தகவல்களை பெற பயன்படுத்தலாம்.\n",
    "- **Wolfram Alpha** - சிக்கலான கணித கணக்கீடுகளுக்கு பயன்படுத்தலாம், எனவே உங்கள் சொந்த செயல்பாடுகளை எழுத வேண்டிய அவசியமில்லை.\n",
    "\n",
    "நீங்கள் LLM அழைக்கக்கூடிய தனிப்பயன் கருவிகளை உருவாக்கவும் முடியும்.\n",
    "\n",
    "கீழே உள்ள குறியீட்டு உதாரணத்தில்:\n",
    "\n",
    "- கிடைக்கக்கூடிய கருவிகளை (brave_search, wolfram_alpha) அமைப்பு உத்தரவில் வரையறுக்கிறோம்.\n",
    "- ஒரு குறிப்பிட்ட நகரத்தின் வானிலை பற்றி கேட்கும் பயனர் உத்தரவை அனுப்புகிறோம்.\n",
    "- LLM Brave Search கருவியை அழைக்கும் ஒரு கருவி அழைப்புடன் பதிலளிக்கும், இது இவ்வாறு இருக்கும் `<|python_tag|>brave_search.call(query=\"Stockholm weather\")`.\n",
    "\n",
    "*குறிப்பு: இந்த உதாரணம் கருவி அழைப்பை மட்டுமே செய்கிறது; நீங்கள் முடிவுகளைப் பெற விரும்பினால், Brave API பக்கத்தில் ஒரு இலவச கணக்கை உருவாக்கி செயல்பாட்டை வரையறுக்க வேண்டும்.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"meta-llama-3.1-405b-instruct\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "\n",
    "tool_prompt=f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 23 July 2024\n",
    "\n",
    "You are a helpful assistant<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=tool_prompt),\n",
    "    UserMessage(content=\"What is the weather in Stockholm?\"),\n",
    "\n",
    "]\n",
    "\n",
    "response = client.complete(messages=messages, model=model_name)\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### லாமா 3.2\n",
    "\n",
    "லாமா 3.1 ஒரு பெரிய மொழி மாதிரி (LLM) என்றாலும், அதன் ஒரு குறைபாடு பல்வேறு வகையான உள்ளீடுகளை (multimodality) பயன்படுத்த முடியாதது. அதாவது, படங்களை போன்ற பல்வேறு வகையான உள்ளீடுகளை உந்துதலாக (prompt) பயன்படுத்தி பதில்களை வழங்கும் திறன். இந்த திறன் லாமா 3.2 இன் முக்கிய அம்சங்களில் ஒன்றாகும். இந்த அம்சங்களில் அடங்கும்:\n",
    "\n",
    "- பல்வேறு வகையான உள்ளீடுகள் (Multimodality) - உரை மற்றும் பட உந்துதல்களை மதிப்பீடு செய்யும் திறன் கொண்டது\n",
    "- சிறிய மற்றும் நடுத்தர அளவிலான மாறுபாடுகள் (11B மற்றும் 90B) - இது தகுதியாக மாறும் பயன்பாட்டு விருப்பங்களை வழங்குகிறது\n",
    "- உரை மட்டும் கொண்ட மாறுபாடுகள் (1B மற்றும் 3B) - இது மாதிரியை எட்ஜ் / மொபைல் சாதனங்களில் பயன்படுத்த அனுமதிக்கிறது மற்றும் குறைந்த தாமதத்தை வழங்குகிறது\n",
    "\n",
    "பல்வேறு வகையான உள்ளீடுகளுக்கான ஆதரவு திறன் திறந்த மூல மாதிரிகளின் உலகில் ஒரு பெரிய முன்னேற்றமாகும். கீழே கொடுக்கப்பட்டுள்ள குறியீட்டு உதாரணம் ஒரு படம் மற்றும் உரை உந்துதலை பயன்படுத்தி, லாமா 3.2 90B மூலம் படத்தின் பகுப்பாய்வை பெறுகிறது.\n",
    "\n",
    "### லாமா 3.2 உடன் பல்வேறு வகையான உள்ளீடுகளுக்கான ஆதரவு\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"Llama-3.2-90B-Vision-Instruct\"\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that describes images in details.\"\n",
    "        ),\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                TextContentItem(text=\"What's in this image?\"),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl.load(\n",
    "                        image_file=\"sample.jpg\",\n",
    "                        image_format=\"jpg\",\n",
    "                        detail=ImageDetailLevel.LOW)\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## கற்றல் இங்கே நிற்கவில்லை, பயணத்தை தொடருங்கள்\n",
    "\n",
    "இந்த பாடத்தை முடித்த பிறகு, உங்கள் Generative AI அறிவை மேலும் மேம்படுத்த [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) ஐ பாருங்கள்!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**குறிப்பு**:  \nஇந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையைப் பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. நாங்கள் துல்லியத்திற்காக முயற்சிக்கிறோம், ஆனால் தானியங்கி மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறான தகவல்கள் இருக்கக்கூடும் என்பதை கவனத்தில் கொள்ளவும். அதன் தாய்மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்கள் அல்லது தவறான விளக்கங்களுக்கு நாங்கள் பொறுப்பல்ல.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "da4ecf6a45fc7f57cd1bdc8fe6847832",
   "translation_date": "2025-10-11T12:07:25+00:00",
   "source_file": "21-meta/python/githubmodels-assignment.ipynb",
   "language_code": "ta"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}