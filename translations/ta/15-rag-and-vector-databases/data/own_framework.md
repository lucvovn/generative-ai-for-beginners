<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df98b2c59f87d8543135301e87969f70",
  "translation_date": "2025-10-11T11:16:58+00:00",
  "source_file": "15-rag-and-vector-databases/data/own_framework.md",
  "language_code": "ta"
}
-->
# நியூரல் நெட்வொர்க்குகளுக்கான அறிமுகம். மல்டி-லேயர்ட் பெர்செப்ட்ரான்

முந்தைய பகுதியில், நீங்கள் மிகவும் எளிய நியூரல் நெட்வொர்க்கு மாடல் - ஒரு லேயர் பெர்செப்ட்ரான், ஒரு நேரியல் இரு வகை வகைப்படுத்தல் மாடல் பற்றி கற்றுக்கொண்டீர்கள்.

இந்த பகுதியில், இந்த மாடலை மேலும் நெகிழ்வான ஒரு கட்டமைப்பாக விரிவாக்குவோம், இது எங்களுக்கு கீழ்க்கண்டவற்றை செய்ய அனுமதிக்கும்:

* **பல வகை வகைப்படுத்தல்** செய்ய, இரு வகை வகைப்படுத்தலுக்கு கூடுதலாக
* **மறுமொழி பிரச்சினைகளை** தீர்க்க, வகைப்படுத்தலுக்கு கூடுதலாக
* நேரியல் முறையில் பிரிக்க முடியாத வகைகளை பிரிக்க

மேலும், Python-இல் நாங்கள் எங்கள் சொந்த மாடுலர் கட்டமைப்பை உருவாக்குவோம், இது நியூரல் நெட்வொர்க்கு கட்டமைப்புகளை உருவாக்க அனுமதிக்கும்.

## மெஷின் லெர்னிங்-இன் முறையான வடிவமைப்பு

மெஷின் லெர்னிங் பிரச்சினையை முறையாக வடிவமைப்பதிலிருந்து தொடங்குவோம். **X** என்ற பயிற்சி தரவுத்தொகுப்பும் **Y** என்ற லேபிள்களும் உள்ளன என்று கருதுவோம், மேலும் மிகச் சரியான கணிப்புகளை செய்யும் ஒரு மாடல் *f* உருவாக்க வேண்டும். கணிப்புகளின் தரம் **இழப்பு செயல்பாடு** &lagran; மூலம் அளவிடப்படுகிறது. பின்வரும் இழப்பு செயல்பாடுகள் அடிக்கடி பயன்படுத்தப்படுகின்றன:

* ஒரு மறுமொழி பிரச்சினைக்காக, எண் ஒன்றை கணிக்க வேண்டும் என்றால், **முழுமையான பிழை** &sum;<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>| அல்லது **சதுர பிழை** &sum;<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup> பயன்படுத்தலாம்.
* வகைப்படுத்தலுக்காக, **0-1 இழப்பு** (இது மாடலின் **துல்லியத்துடன்** அடிப்படையில் ஒரே மாதிரியானது), அல்லது **லாஜிஸ்டிக் இழப்பு** பயன்படுத்தப்படுகிறது.

ஒரு லேயர் பெர்செப்ட்ரானுக்கான *f* செயல்பாடு *f(x)=wx+b* என்ற நேரியல் செயல்பாடாக வரையறுக்கப்பட்டது (இங்கு *w* என்பது எடை மாட்ரிக்ஸ், *x* என்பது உள்ளீட்டு அம்சங்களின் வெக்டர், மற்றும் *b* என்பது பைஸ் வெக்டர்). வெவ்வேறு நியூரல் நெட்வொர்க்கு கட்டமைப்புகளுக்கு, இந்த செயல்பாடு மேலும் சிக்கலான வடிவத்தை எடுக்கலாம்.

> வகைப்படுத்தலின் போது, தொடர்புடைய வகைகளின் சாத்தியக்கூறுகளை நெட்வொர்க்கின் வெளியீடாக பெறுவது விரும்பத்தக்கது. சாத்தியக்கூறுகளாக மாற்றுவதற்கு (எ.கா., வெளியீட்டை சாதாரணமாக்க), **softmax** செயல்பாடு &sigma; அடிக்கடி பயன்படுத்தப்படுகிறது, மேலும் *f* செயல்பாடு *f(x)=&sigma;(wx+b)* ஆக மாறுகிறது.

மேலே உள்ள *f* வரையறையில், *w* மற்றும் *b* **அளவுருக்கள்** &theta;=⟨*w,b*⟩ என்று அழைக்கப்படுகின்றன. ⟨**X**,**Y**⟩ என்ற தரவுத்தொகுப்பை வழங்கியபின், முழு தரவுத்தொகுப்பில் உள்ள மொத்த பிழையை அளவுருக்களுக்கான செயல்பாடாக கணிக்கலாம்.

> ✅ **நியூரல் நெட்வொர்க்கு பயிற்சியின் நோக்கம் அளவுருக்களை &theta; மாறுவதன் மூலம் பிழையை குறைப்பதாகும்**

## கிரேடியண்ட் டிசென்ட் ஆப்டிமைசேஷன்

**கிரேடியண்ட் டிசென்ட்** என்று அழைக்கப்படும் ஒரு பிரபலமான செயல்பாடு ஆப்டிமைசேஷன் முறை உள்ளது. இதன் யோசனை என்னவென்றால், இழப்பு செயல்பாட்டின் அளவுருக்களுக்கான டெரிவேட்டிவ் (பல பரிமாணக் கேஸில் **கிரேடியண்ட்** என்று அழைக்கப்படும்) கணிக்க முடியும், மேலும் பிழை குறையும்படி அளவுருக்களை மாற்ற முடியும். இதை பின்வருமாறு முறையாக வடிவமைக்கலாம்:

* w<sup>(0)</sup>, b<sup>(0)</sup> என்ற சில சீரற்ற மதிப்புகளால் அளவுருக்களை தொடங்கவும்
* பின்வரும் படியை பல முறை மீண்டும் செய்யவும்:
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-&eta;&part;&lagran;/&part;w
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-&eta;&part;&lagran;/&part;b

பயிற்சியின் போது, ஆப்டிமைசேஷன் படிகள் முழு தரவுத்தொகுப்பை கருத்தில் கொண்டு கணிக்கப்பட வேண்டும் (இழப்பு அனைத்து பயிற்சி மாதிரிகளின் மூலம் ஒரு தொகையாக கணக்கிடப்படுகிறது என்பதை நினைவில் கொள்ளுங்கள்). ஆனால், உண்மையான வாழ்க்கையில், **minibatches** என்று அழைக்கப்படும் தரவுத்தொகுப்பின் சிறிய பகுதிகளை எடுப்போம், மேலும் தரவின் ஒரு துணுக்கின் அடிப்படையில் கிரேடியண்ட்களை கணிக்கிறோம். ஒவ்வொரு முறையும் சீரற்ற முறையில் துணுக்குகள் எடுக்கப்படுவதால், இந்த முறை **stochastic gradient descent** (SGD) என்று அழைக்கப்படுகிறது.

## மல்டி-லேயர்ட் பெர்செப்ட்ரான்கள் மற்றும் பாக்ப்ரொபகேஷன்

ஒரு லேயர் நெட்வொர்க்கு, மேலே பார்த்தபடி, நேரியல் முறையில் பிரிக்கக்கூடிய வகைகளை வகைப்படுத்த முடியும். மேலும் செறிவான மாடலை உருவாக்க, நெட்வொர்க்கின் பல லேயர்களை இணைக்கலாம். கணித ரீதியாக, *f* செயல்பாடு மேலும் சிக்கலான வடிவத்தை எடுக்கும், மேலும் பல படிகளில் கணக்கிடப்படும்:
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>&alpha;(z<sub>1</sub>)+b<sub>2</sub>
* f = &sigma;(z<sub>2</sub>)

இங்கு, &alpha; என்பது **நேரியல் அல்லாத செயல்பாடு**, &sigma; என்பது softmax செயல்பாடு, மற்றும் அளவுருக்கள் &theta;=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*>.

கிரேடியண்ட் டிசென்ட் ஆல்காரிதம் மாறாமல் இருக்கும், ஆனால் கிரேடியண்ட்களை கணக்கிடுவது சிக்கலாக இருக்கும். சங்கிலி வேறுபாட்டு விதியை கருத்தில் கொண்டு, டெரிவேட்டிவ்களை பின்வருமாறு கணக்கிடலாம்:

* &part;&lagran;/&part;w<sub>2</sub> = (&part;&lagran;/&part;&sigma;)(&part;&sigma;/&part;z<sub>2</sub>)(&part;z<sub>2</sub>/&part;w<sub>2</sub>)
* &part;&lagran;/&part;w<sub>1</sub> = (&part;&lagran;/&part;&sigma;)(&part;&sigma;/&part;z<sub>2</sub>)(&part;z<sub>2</sub>/&part;&alpha;)(&part;&alpha;/&part;z<sub>1</sub>)(&part;z<sub>1</sub>/&part;w<sub>1</sub>)

> ✅ சங்கிலி வேறுபாட்டு விதி இழப்பு செயல்பாட்டின் அளவுருக்களுக்கான டெரிவேட்டிவ்களை கணக்கிட பயன்படுத்தப்படுகிறது.

இந்த வெளிப்பாடுகளின் இடது பகுதி எல்லா இடங்களிலும் ஒரே மாதிரியானது, எனவே இழப்பு செயல்பாட்டிலிருந்து தொடங்கி கணக்கீட்டு வரைபடத்தின் மூலம் "பின்புறம்" செல்லும் வகையில் டெரிவேட்டிவ்களை கணக்கிடலாம். எனவே, மல்டி-லேயர்ட் பெர்செப்ட்ரானை பயிற்சியிடும் முறை **பாக்ப்ரொபகேஷன்** அல்லது 'பாக்ப்ரொப்' என்று அழைக்கப்படுகிறது.

> TODO: படம் மேற்கோள்

> ✅ நாங்கள் பாக்ப்ரொபகேஷனை எங்கள் நோட்புக் எடுத்துக்காட்டில் மேலும் விரிவாகக் கையாளுவோம்.

## முடிவு

இந்த பாடத்தில், நாங்கள் எங்கள் சொந்த நியூரல் நெட்வொர்க்கு நூலகத்தை உருவாக்கியுள்ளோம், மேலும் அதை எளிய இரு-பரிமாண வகைப்படுத்தல் பணிக்குப் பயன்படுத்தியுள்ளோம்.

## 🚀 சவால்

இணைக்கப்பட்ட நோட்புக்கில், நீங்கள் மல்டி-லேயர்ட் பெர்செப்ட்ரான்களை உருவாக்கவும் பயிற்சியிடவும் உங்கள் சொந்த கட்டமைப்பை செயல்படுத்துவீர்கள். நவீன நியூரல் நெட்வொர்க்குகள் எப்படி செயல்படுகின்றன என்பதை விரிவாகக் காணலாம்.

OwnFramework நோட்புக்கிற்கு செல்லவும் மற்றும் அதைச் செயல்படுத்தவும்.

## மதிப்பீடு மற்றும் சுயபயிற்சி

பாக்ப்ரொபகேஷன் AI மற்றும் ML-இல் பொதுவாகப் பயன்படுத்தப்படும் ஒரு ஆல்காரிதமாகும், மேலும் அதை மேலும் விரிவாகக் கற்க வேண்டியது அவசியம்.

## பணிக்கட்டளை

இந்த ஆய்வகத்தில், இந்த பாடத்தில் நீங்கள் உருவாக்கிய கட்டமைப்பைப் பயன்படுத்தி MNIST கை எழுத்து இலக்க வகைப்படுத்தலை தீர்க்க வேண்டும்.

* வழிமுறைகள்
* நோட்புக்

---

**குறிப்பு**:  
இந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையைப் பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. நாங்கள் துல்லியத்திற்காக முயற்சிக்கிறோம், ஆனால் தானியக்க மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறான தகவல்கள் இருக்கக்கூடும் என்பதை தயவுசெய்து கவனத்தில் கொள்ளுங்கள். அதன் தாய்மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்கள் அல்லது தவறான விளக்கங்களுக்கு நாங்கள் பொறுப்பல்ல.